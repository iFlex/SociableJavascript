DONE >> 1) figure out how to restrict heap size of context (for whole v8 instance)
* restricts the old_space_size, I wonder if semi_space_size is relevant to this

DONE >> 1.1) figure out how to tell when program completes successfully - proposed solution > program outputs unique message to STDOUT
* Used return value

DONE >> 2) find the minimum heap size required for each benchmark ( binary search )
DONE >> 3) graph - max heap size to mean execution time
DONE >> 4) matplotlib
DONE >> 5) rerun same benchmark to ensure heap size is correct - js wrappers

DONE >> 6) Update Readme
DONE >> 7) v8wrapper.js takes in list of required scripts
DONE >> 8) Pithon live plotting class - need to make class instance it own the plot window or plot, allow clearing data and restarting plot


DONE >> 1) Binary Tree Benchmark test
2) Make benchmark that allocates a lot of memory and moves it
DONE >> 3) Look at Gregor R. Benchmark papers +
DONE >> 4) Regenerate graphs with tiny semi-space
DONE >> 5) 1-6 min heap size graph granularity 1/3
DONE >> 6) Can the max heap size be resized dynamically
* Apparent answer is yes - the heap grows on demand and stops when it reaches the hard limits,
by changing the hard limits at runtime, the heap space should adapt

both expand and shrink are supported
- did not observe cohesion between max_old_space_ from Heap and PagedSpace's max_capacity
so caution when expanding and shrinking -> all stat values need to be updated

# Prediction: the ExpandSpace() and Shrink need to be called from a thread safe context.
Explore the thread model ( Isolates are contexts that the threads enter and execute.
If a thread exits an Isolate it's not guaranteed it will resume it, another may step in and continue the work )

NO_NEED >> 7) Check if Isolate objects can be suspended/resumed

DONE >> 8) Export the ExpandSpace method for the old_space_ to JS - Did not work
DONE >> 8.1) Added a setMaxOldSpace in heap.h/cc that sets the max_old_generation_space hard limit
DONE >> 9) Export method for GetAvailableSpace of old_space_ to JS if not existing
HALF >> 10) Make benchmark that plays with memory and expands and shrinks
NO_NEED >> 11) try GDB with V8 to debug JS
DONE >> 12) Look for debug funcitonality for JS
DONE >> 13) V8 memory profiler reasearch

DONE >> 15) Get external Python process comm. with V8 to change the heap size
DONE >> 16) Read paper Heap Sizing
nonessential_17) Consider how DOS may occur & consider mitigation
DONE >> 19) Take a look at build process of v8 to add new files to the build
DONE >> 20) Devise a simple protocol for the v8 overlord server thread
  some queries that are going to publicise the state of the v8 heap
  some commands that are going to alter the size of the v8 heap

DONE >> 21) Do a test on different machines
DONE >> 22) Download Chrome codebase see where v8 is in the project
DONE >> 23) Figure out how to get all isolates in a list to make an overall daemon
DONE >> 24) Figure out a way to measure Isolate throughput
 * using GC prologue and epilogue hooks and timer

DONE >> 25) Identify the start and end of GC process
GCprologue/epilogue hook
examples in test files. just search for invocations of AddGCPrologueCallback

DONE >> 27) Check what performance metrics V8 measures and get access to them
D8 - generates plottable information but goes deep into program stack and heap nodes which makes in unnecessary and adds overhead
using own calculated throughput

DONE >> 28) Integrate JSON protocol in Overlord + make CLI controller
DONE >> 29) Draft progress report by next Monday
26) Unit tests for good SE practices + dissertation talk
DONE >> 27) Use GC hooks to measure GC pauses and do data analysis. Pause time vs exec time, + distribution analysis with bins
* use to decide how to supply metrics to the overlord thread
max, median, avg
DONE >> 28) Look at benchmarks from Phd Student
29) Raspberry Pi install script and testing if the framwework works
DONE >> 30) Early dissertation task
DONE >> 31) Determine the nature of the evaluation. Read through Blair's dissertation evaluation.
32) Explore d8, Visual VM, Intel Vtune, GCspy
DONE >> 33) Implement policy
DONE >> 34) Timing, HeapSize, UsedMemory - factor into policy
DONE >> 35) Aggregator per machine - total memory used
DONE >> 36) Pluggability of Ploicy - descriptor file that can be interpreted by the policy.py so that any policy can be used
DONE >> 37) Improve mock v8 to allow Jeremy to write and test policy, report from existing CSV files rather than random value
DONE >> 38) Implement Robin Hood Policy

*D* evaluation of the monitor
*D* talk about testing

*1Lt) Use the python monitor to control a cluster of V8 instances on a Distributed Raspberry Pi Cluster

* Norm for Garbage Collection aware OS norm
* Keep security in mind
* Mention implementation trick to improve rendering of graphs

*D*
Dissertation - >
 * Tech overview of V8
 * Mem management
 * controlling heap size
 * Unit Testing...

find -name "*.cc" -or -name "*.cpp" -or -name "*.h" | xargs wc -l

List of tricks:
Use the max_old_space_size to forge GC to do all the deallocation work. Space expands by itself anyway
Skip Rendering Phases to Preserve Frame Rate
Pluggable policy so anyone can write one
Component oriented testing
TCP/IP for distributed use
Multi Processing for better live plotting
