\pdfoutput=1

\documentclass{l4proj}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{url}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{dirtree}

\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = black %Colour of citations
}

\colorlet{punct}{red!60!black}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\definecolor{darkgray}{rgb}{0.4, 0.4, 0.4}
%\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{editorGray}{rgb}{0.95, 0.95, 0.95}
\definecolor{editorOcher}{rgb}{1, 0.5, 0} % #FF7F00 -> rgb(239, 169, 0)
\definecolor{editorGreen}{rgb}{0, 0.5, 0} % #007C00 -> rgb(0, 124, 0)
\definecolor{orange}{rgb}{1,0.45,0.13}    
\definecolor{olive}{rgb}{0.17,0.59,0.20}
\definecolor{brown}{rgb}{0.69,0.31,0.31}
\definecolor{purple}{rgb}{0.38,0.18,0.81}
\definecolor{lightblue}{rgb}{0.1,0.57,0.7}
\definecolor{lightred}{rgb}{1,0.4,0.5}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
%V8 C++
\lstdefinelanguage{cpp}{
  morekeywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break,Isolate,CreateParams,New},
  morecomment=[s]{/*}{*/},
  morecomment=[l]//,
  morestring=[b]",
  morestring=[b]'
}
% CSS
\lstdefinelanguage{CSS}{
  keywords={color,background-image:,margin,padding,font,weight,display,position,top,left,right,bottom,list,style,border,size,white,space,min,width, transition:, transform:, transition-property, transition-duration, transition-timing-function}, 
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]',
  morestring=[b]",
  alsoletter={:},
  alsodigit={-}
}

% JavaScript
\lstdefinelanguage{JavaScript}{
  morekeywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  morecomment=[s]{/*}{*/},
  morecomment=[l]//,
  morestring=[b]",
  morestring=[b]'
}

\lstdefinelanguage{HTML5}{
  language=html,
  sensitive=true, 
  alsoletter={<>=-},  
  morecomment=[s]{<!-}{-->},
  tag=[s],
  otherkeywords={
  % General
  >,
  % Standard tags
  <!DOCTYPE,
  </html, <html, <head, <title, </title, <style, </style, <link, </head, <meta, />,
  % body
  </body, <body,
  % Divs
  </div, <div, </div>, 
  % Paragraphs
  </p, <p, </p>,
  % scripts
  </script, <script,
  % More tags...
  <canvas, /canvas>, <svg, <rect, <animateTransform, </rect>, </svg>, <video, <source, <iframe, </iframe>, </video>, <image, </image>, <header, </header, <article, </article
  },
  ndkeywords={
  % General
  =,
  % HTML attributes
  charset=, src=, id=, width=, height=, style=, type=, rel=, href=,
  % SVG attributes
  fill=, attributeName=, begin=, dur=, from=, to=, poster=, controls=, x=, y=, repeatCount=, xlink:href=,
  % properties
  margin:, padding:, background-image:, border:, top:, left:, position:, width:, height:, margin-top:, margin-bottom:, font-size:, line-height:,
  % CSS3 properties
  transform:, -moz-transform:, -webkit-transform:,
  animation:, -webkit-animation:,
  transition:,  transition-duration:, transition-property:, transition-timing-function:,
  }
}
\lstdefinestyle{htmlcssjs} {%
  % General design
%  backgroundcolor=\color{editorGray},
  basicstyle={\tiny},   
  frame=b,
  % line-numbers
  xleftmargin={0.75cm},
  numbers=left,
  stepnumber=1,
  firstnumber=1,
  numberfirstline=true, 
  % Code design
  identifierstyle=\color{black},
  keywordstyle=\color{blue}\bfseries,
  ndkeywordstyle=\color{editorGreen}\bfseries,
  stringstyle=\color{editorOcher}\ttfamily,
  commentstyle=\color{brown}\ttfamily,
  % Code
  language=HTML5,
  alsolanguage=JavaScript,
  alsodigit={.:;},  
  tabsize=2,
  showtabs=false,
  showspaces=false,
  showstringspaces=false,
  extendedchars=true,
  breaklines=true,
  % German umlauts
  literate=%
  {Ö}{{\"O}}1
  {Ä}{{\"A}}1
  {Ü}{{\"U}}1
  {ß}{{\ss}}1
  {ü}{{\"u}}1
  {ä}{{\"a}}1
  {ö}{{\"o}}1
}
%
\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                     % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\begin{document}
\title{Sociable Javascript}
\author{Milorad Liviu Felix}
\date{\today}
\maketitle
\educationalconsent
%
%NOTE: if you include the educationalconsent (above) and your project is graded an A then
%      it may be entered in the CS Hall of Fame
%
\newpage
\begin{abstract}
   As \textbf{JavaScript} has grown in popularity, it has also became more versatile. More applications running JavaScript on the same machine may result in greater memory contention among processes. To make the best use of system resources while maximising utilisation, the applications would need to be aware of each other's memory needs, and cooperate in order for them to continuously have access to the minimum running requirements. To achieve system-wide awareness at an individual application level, we propose a client-server model, where a manager process keeps track of all running client applications and controls how much memory they are allocated. We present a set of policies based on social welfare theory that model JavaScript execution environments as individuals and evaluate how they impact the execution speed and memory footprint of each application. An application with a low memory footprint, that has acceptable throughput, could make JavaScript a suitable choice for highly multiprocessing and elastic systems.
\end{abstract}
\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}
\chapter{Introduction}
%intro
\hspace*{3em} \textbf{JavaScript} is a highly dynamic language for web-based applications.\cite{intro}!!-!!-!!-!!%abstract. need to add anectode about how everything is modeled as an object and that is hard to interpret/exec 
 It began as a simple solution for animating web-page content, but has evolved into a \textbf{multipurpose scripting language} with growing support and popularity. A large part of the functionality of web products is now implemented in JavaScript and there are initiatives, such as NodeJS\cite{nodejs}, that aim to bring this language to the \textbf{server side}. Since the language is interpretive, browser vendors implement JavaScript \textbf{virtual machines} that perform \textbf{just-in-time} compilation to execute the code. Some of the most widely used examples are \textbf{V8} from Google Chrome\cite{v8}, Nitro from Apple Safari, Spidermonkey\cite{spidermk} from Mozilla Firefox and Chakra\cite{chakra} from Microsoft Edge.
\\\\%garbage collection
\hspace*{3em} One reason for the \textbf{considerable popularity} of the language is its \textbf{simplicity}. A key factor of this simplicity is that JavaScript programmers do not have to handle memory. This allows developers to focus on the high level functionality such as how an application responds to a certain request rather than on low level implementation details such as how much memory a new object needs and when that memory should be freed. The responsibility of memory management is passed onto the virtual machine that executes the program. While \textbf{memory allocation} may be straight forward (a new block of memory is requested from the host operating system when the application creates a new object), \textbf{freeing memory} cannot be done in the same manner, as an object that goes out of scope might still be referenced by a \textbf{live object}. The virtual machine needs to inspect the live objects and detect which ones have truly expired and free the memory they occupy. This process is called \textbf{garbage collection}.
\\\\%virtual machines optimisations
\section{Virtual Machine Optimisation}
\hspace*{3em} These \textbf{JavaScript virtual machines} are optimised to offer the best possible performance from a user perspective, this means that speed of execution and steady rendering are most important. In the case of V8, the engineers that designed it are using the term \textbf{``jank''} to refer to noticeable rendering pauses caused by JavaScript garbage collection and are currently striving to minimise it. One example of jank is when the user scrolls the page and the animation has noticeable pauses that make it look \textbf{discontinuous}. Jank occurs because in order to carry out garbage collection the execution of the JavaScript application needs to be paused. To reduce the impact observable by the user, garbage collection pauses are divided into small execution sequences and are interleaved with long execution sequences. This improves the user experience but increases the memory footprint of the application as unused memory is held for longer than necessary. Such a system is not concerned with conserving memory and cooperating with other processes in order to allow as many applications as possible to run on the system, but this behavior is justified as each tab in the browser needs to display as smoothly as possible.
\\\\%server side applications
%TODO: add some examples of nodejs services
\section{Multipurpose JavaScript}
\hspace*{3em} \textbf{JavaScript outgrew its original intended purpose} and has expanded to \textbf{server side applications} and native \textbf{client applications}. In the case of server side applications, the NodsJS framework is experiencing a growing adoption trend for services such as web-servers, push notification servers, server side voice recognition and other computation bound services. This is in part due to the fact that a large majority of the JavaScript library ecosystem is compatible with NodeJS leaving out only the libraries that utilise HTML document related methods and structures (which are not present in NodeJS). In this case, jank does not exist since no rendering is done, therefore garbage collection would only impact total execution time. Service providers would greatly benefit if these applications were to have a lower memory footprint (achieved by collecting garbage more intensely) as more processes can be run per single physical machine, thus increasing the service availability. Also being able limit memory expansion per process guarantees that system processes and other service specific administrative processes will always have enough memory to remain responsive, regardless of how loaded the client serving applications are. Elastic systems can benefit from a global service that controls memory usage of garbage collected systems as the limits can be tightened or relaxed depending on the load and total amount of memory made available at each point in time.\\%client side applications
\\\\
\hspace*{3em} JavaScript based \textbf{client side applications} are also beginning to emerge in the form of NWJS(Node Webkit JavaScript) applications. In essence this is a web browser rendering a local webpage which has access to JavaScript file system APIs and other native application functionality that is normally not included in regular web browsers for security reasons. This approach is gaining popularity especially among organisations that lack the human resources necessary to build different native applications for each platform they intend to support or want to deploy their existing web applications in the form of native applications. 
Examples of such native applications are: Powder Player - a video streaming application with torrent download and seeding integration\cite{powderplayer}, WhatsApp - a popular messenger application acquired by Facebook in 2014 \cite{whatsap}, Facebook’s messenger - Facebook's own messenger platform \cite{messenger}, DevKit - a modular integrated development environment \cite{devkit},
Wunderlist - a popular productivity application allowing users to create and share task lists\cite{wunderlist} and even a game named GameDev Tycoon\cite{tycoongame}. 
%kind of weak
Having a mechanism for controlling such an application's memory usage would allow the user to run many JavaScript applications concurrently while using an optimum amount of memory so that all the other processes can complete successfully. This way the user can play a game while listening to music and streaming files from the internet, all using JavaScript applications.
\\\\%purpose of the project
\section{Project Scope}
\hspace*{3em} The purpose of this project is to build a framework capable of \textbf{monitoring the memory usage} of every JavaScript running context and apply a memory management policy that will generate a limit for each one of them. Upon receiving its memory limit from the manager the JavaScript virtual machine will free more memory during garbage collection in order to comply.
\\\\ %motivation and social welfare
\hspace*{3em} The motivation for building such a system is improving the maximum possible \textbf{multi-programming degree}, availability and fault tolerance for services based on JavaScript applications, making this technology suitable for \textbf{multi-tasking and elastic systems}. The main benefit of enforcing a global memory utilisation policy over all of the JavaScript running contexts on a machine is reducing competition for resources and increasing cooperation. Garbage collection will be done more frequently, thus freeing up more memory and allowing more instances to run on the same machine. The end goal would be to increase the multi-programming level without hindering performance.\\
\hspace*{3em} Through the coordinated management of memory based on global information, applications achieve a form of cooperation much like individuals cooperate and responsibly share resources with each other, in order to maintain a necessary level of comfort. The key factor to the success of this framework would be to maintain acceptable throughput levels for each JavaScript appliaction. This translates directly to how long each program takes to complete. If execution time increases considerably, the applications become unfeasible. In order to find a balance between throughput and memory size, the framework models execution contexts as individuals and applies a social welfare function in order to determine how much memory each individual is allowed to use. We will attempt to build such a cooperative memory manager using concepts from \textbf{social welfare theory}.
\\\\
There are two main components to this project:
\begin{itemize}
\item The \textbf{manager} - receives memory usage information, applies the management policy and then issues limits to each execution environment.
\item a modified \textbf{JavaScript virtual machine} executes JavaScript, reports runtime context characteristics (heap size, throughput, etc) and enforces memory limits received from the manager.
\end{itemize}
The manager is a Python application and the virtual machine selected for this project is Google's V8 engine. The manager will be central to evaluating the performance of each script in relation to the applied policy using the characteristics received from the V8.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.75\textwidth]{SimplifiedOverall.png}
    \caption{Overall project diagram.}
\end{figure}

The approach adopted was similar to the Java Forseti system developed at the University of Glasgow\cite{forseti}. To implement this system, changes need to be done to the V8 engine and a manager process that would implement the policy would need to be built. The V8 engine would need modifications that allow dynamic expanding and shrinking of a running context's (isolate) heap size and a network client that receives and executes commands issued by the manager. This can be a challenging task since the V8 project consists of \textbf{800,000+ lines of code}. %diagram

%The system would work as follows: the manager process starts a registry server that listens for connections from V8 instances. A new V8 instance would run either by itself or inside the Chrome browser and would connect to the manager process. As soon as the manager detects a new V8 instance, it starts polling it for status information (heap memory used, throughput, etc). The manager will use this information to calculate how large the heap of each isolate should be and will send the calculated value back to the V8. The engine will then try to adapt each isolate's memory consumption to match the recommended value by increasing the number of garbage collection operations.
%expand
\section{Outline}

Below is the structure of this report:

\textbf{Chapter 2 - Background:}
Background information

\textbf{Chapter 3 - Requirements:}
Functional and non-functional requirements of the management framework.

\textbf{Chapter 4 - Design:}
Design of the management framework as well as of the required changes to the V8 engine.

\textbf{Chapter 5 - Implementation}
Implementation of the management framework and of the changes to V8.

\textbf{Chapter 6 - Evaluation:}
Empirical evaluation of the effectiveness of the framework when using various memory management policies.

\textbf{Chapter 7 - Conclusions}
Conclusions and future advances.


\chapter{Background}
%java script
%garbage collection
%v8
CHAPTER DESCRIPTION
\section{Welfare Economics}
\hspace*{3em} \textbf{Welfare economics} is a branch of economics that uses microeconomic techniques to evaluate well-being (welfare) at the aggregate (economy-wide) level.\cite{welfareeconomics} The typical evaluation begins with the derivation of a \textbf{social welfare function}. In welfare economics, a social welfare function is a function that ranks social states (alternative complete descriptions of the society) as less desirable, more desirable, or indifferent for every possible pair of social states. Inputs of the function include any variables considered to affect the economic welfare of a society.\cite{socialwelfarefunction} This is then used to rank economically feasible allocations of resources. JavaScript applications can be modeled as individuals using a a combination of the characteristics of running contexts as input values for the social welfare function. Such characteristics are heap size, available memory, throughput, etc. The exact choice of the social welfare function, selected set of runtime context characteristics and the way these characteristics are mapped to the input values of the function are what we call a \textbf{policy}. This project aims to evaluate the effectiveness of various policies in relation to different types of JavaScript applications: web pages scripts, IO bound standalone applications, computation bound standalone applications. Some policies may be better suited for standalone applications while others may work work well with web-page scripts, some might perform well overall. 
\section{JavaScript}
\hspace*{3em} In 1994, \textbf{Netscape} developed a web browser that was meant to exploit the potential of the emerging \textbf{World Wide Web}, its name was Netscape Navigator. The engineers behind the browser quickly realized that the Web needed to be more dynamic as even basic input validation had to be done by the server (requiring the browser to send the data over the network to the server and receive feedback). Later in 1995, a debate began among the engineers at Netscape about whether to add a static or scripting language to their browser. The proponents of a scripting language offered the following explanation:\cite{jsgrandpa} 
\textit{``We aimed to provide a “glue language” for the Web designers and part time programmers who were building Web content from components such as images, plugins, and Java applets. We saw Java as the “component language” used by higher-priced programmers, where the glue programmers—the Web page designers—would assemble components and automate their interactions using [a scripting language].''}
Netscape management had decided that a scripting language had to have a syntax similar to Java’s largely because of their collaboration with \textbf{Sun}, the company that created the \textbf{Java programming language}. In late November 1995, Navigator 2.0B3 came out and included the prototype, which continued its early existence without major changes. In early December 1995, Java’s momentum had grown and the language was renamed, to its final name, \textbf{JavaScript}.\cite{jsdaddy}
\\\\
\hspace*{3em} JavaScript has since grown to be one of the most popular programming languages. If popularity were to be judged by the number of projects built with JavaScript, then it has become the most popular language on GitHub\cite{github} (which in turn is one of the most popular version control services):

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{JsPop.png}
    \caption{JavaScript 1st popular language on GitHub.\cite{githut}}
\end{figure}
The popularity of a programming language comes from the size and activity of its community (the developers that build projects with the said language) and this means that JavaScript has a vast and active one. !!-!!-!!-!!
%add some sort of conclusion = JS could be good to use in backend / native side
\section{Garbage Collection}
%This chapter provides a high level overview of numerous garbage collection techniques including key defini-
%tions which shall be used throughout this report. For a fuller introduction to garbage collection techniques see
%Wilson[18] who presents a comprehensive survey paper of the basic techniques. Many of the basic memory sys-
%tem elements are shown graphically in Figure 2.1. This figure is intended to be used as a reference when reading
%this section.
\begin{figure}[!ht]
  \centering
    \includegraphics[height=15em]{Heap.png}
    \caption{Basic Memory System Diagram}
\end{figure}
\section{Why control resource allocation}
\hspace*{3em} To better portray the benefit of controlling resource allocation, consider an elastic data centre running JavaScript application to service various client requests as well as administrative tasks. The elastic nature of the environment would require increasing or decreasing the number of active host machines as well as the number of active servicing application depending on the load. 
\\\\
\hspace*{3em} Without any supervision, JavaScript application would simply use as much memory as necessary to maximise performance. This would be done without any knowledge or consideration for the other processes running on the host machine. Performance is maximised by keeping garbage collection pauses as short and far apart as possible, causing the program to retain more memory than it actually needs. This would not pose any problems in situations where there is plenty of memory, but as the number of processes running in parallel increases so does the memory contention.
\\\\
\hspace*{3em} In the situation where the available memory was nearly depleted, newly started application would suffer from memory starvation causing them to run with very low throughput or even fail. Existing applications could also suffer as their needs could change over time (a section of code that is more memory intensive executes), as there is no way to coordinate the JavaScript run-time environments in order to maximise the throughput of every application by forcing some to relinquish more memory and giving it to the ones in need. In a situation with no available memory, applications would start trashing which would gravely impact the overall performance of the system. In this scenario, if the system administrator did not reserve an amount of memory for system processes, the operation of the system would slow down considerably or even halt. 
\\\\
\hspace*{3em} With no supervision framework, the system administrator would have to estimate how many applications can run on a machine, depending on the amount of memory each machine has, and enforce such a limit on every machine in the environment. This solution is not viable for a modern elastic environment where the machine count is the thousands and new machines are added or removed depending on system load. 
\\\\
\hspace*{3em} A supervising framework would calculate and enforce a memory limit for every JavaScript application it manages in an effort to maximise their throughput. Managed applications would not be allowed to retain unused memory if there are other applications that need more memory. In contrast with the situation presented above, where no supervisor was present, portions of memory are taken from carefully selected applications and given to the newly started or low throughput programs. The framework can also be configured to assign limits within a certain threshold in order for the total memory consumption of JavaScript programs to be lower than the total available memory. This would offer the guarantee that system processes have a dedicated portion of memory at all times.
\\\\
\hspace*{3em} A JavaScript program would fail only if its assigned memory limit becomes lower than its minimum heap size. Since this size is considerably smaller than the actual unrestricted memory usage (see appendix \cref{minheapsize}), more applications could safely run on the same machine than in the scenario where no supervisor is present. This would increase the productivity and responsiveness potential of a host machine. Knowing the minimum heap size of a program could also enable the framework to perform an acceptance check for new applications starting on host machine:
\begin{equation} 
\textit{AllocatableMemory} = \textit{TotalAllocatableMemory} - \sum_{i=0}^{N}\textit{MinimumHeapSize}_i
\end{equation}
If the value of the expression above is lower than the minimum heap size, the new application can not be allowed to start as it is highly likely to fail. Using this check a machine capable of hosting the new application could be found.
\\\\
\hspace*{3em} A supervisor framework uses insight provided by the running applications to make resource allocation decisions. In a normal setup, this insight is not needed since applications are entitled to an equal share of the system resources by default. This allows any individual application to make demands best suited for its well being without being concerned with the status of the others. Having insight provided by every running applications has the main advantage of allowing a supervisor to work towards the well being of the group rather than of an individual. This way, memory is used more efficiently, more applications can run at the same time and newly started applications are less likely to suffer from memory starvation if the other running applications utilise most of the available memory.
\section{Related Work}
\subsection{Virtual Machine Inspectors}
\hspace*{3em} - already used by industry, too heavy in their analysis - goes too deep - performance cost (proof) or if no performance cost, too much data to analyse.
\subsection{Directly Related Work}
FORSETTI\\
Throughput, Heap curve\\
Control theory?
\chapter{Requirements}
CHAPTER DESCRIPTION
%\hspace*{3em} (Does not really make sense, need to rephrase ->)Due to the exploratory nature of the project at hand, some of the functional and non functional requirements of the system have been drawn based on the features offered either by the V8 engine or by the limitations of the technologies used to build the framework. 
\section{Non-Functional Requirements}
\begin{itemize}
\item Detect V8 instances within the managed environment and apply a selected memory management policy.
\item Control the memory limits for all the Isolates within the managed environment without causing any of them to terminate execution abnormally.
\item Automatically detect new V8 processes and add them to a pool of managed processes.
\item Automatically detect when new Isolates are created by their host V8 processes and add them to a pool of active isolates.
\item Automatically detect when Isolates finish execution and remove them from the pool of active isolates.
\item Automatically detect when V8 processes finish execution, remove all isolates they host from the pool of active isolates and remove the process form the pool of managed processes.
\item Calculate limits at a set frequency for all active isolates.
\item Service a large number of V8 processes without unpredictable delays.
\item Capture every parameter of the isolate updates.
\item Plot selected status features of every isolate in the system on screen for the user to analyse as the framework is running.
\item Save the selected status features of an isolate's entire execution in a file for post-execution analysis.
\item Disable the feedback module so that the application works solely on enforcing memory limits.
\item Give access to features of the entire framework to the user.
\end{itemize}
\section{Functional Requirements}
\begin{itemize}
\item Given a new V8 process connection, update the pools of managed machines, V8s and isolates.
\item Given a new V8 process connection, use the remote IP address as a unique identifier for the host machine, assign a new numeric ID value, unique within the context of the host machine, to represent the V8. Also store the communications channel (socket) used to contact this V8.
\item Given a new Isolate, assign it the same ID used by its host V8 process and store it in the managed isolates pool.
\item Given a Machine Id, V8 Id and an Isolate Id correctly retrieve the status information of the Isolate and the communications channel needed to communicate with its host V8 process.
\item Given a pool of active isolates send a status update request to the correct host V8 processes. 
\item Given a list of isolates and a maximum available memory value and output a list of memory limits for each isolate
\item Given a collection of status values for an isolate, plot the selected (relevant) ones on screen in the window corresponding to the isolate.
\item Given a collection of status values for an isolate, append them to a file containing the full history for that isolate.
%are these non-functional?
\item Allow the user to set the polling frequency of the manager
\item Allow the user to select the memory management policy used to calculate the memory limits.
\item Allow the user to get status information about the managed isolates and other framework facilities.
\item Allow the user to configure the plotting facility behaviour: such as whether a full history file should be created, PNG files should be created or live plotting should be done
\item Allow the user to set memory limits on active isolates
\item Allow the user to set maximum available memory for managed machines
\item Allow the user to run automated testing scenarios to evaluate the existing policies.
\end{itemize}
\newpage
\chapter{Design}
CHAPTER DESCRIPTION
\section{Overview}

The overall framework has two main components:
\begin{itemize}
\item A \textbf{manager} - keeps track of active V8 instances, polls V8 instances for status information periodically, groups and plots the status information, calculates the memory allowance for each V8 Isolate, sends the appropriate commands containing the memory limits.
\item A \textbf{modified V8 engine} - connects to manager, retrieves status information and responds to poll requests and commands, depending on current memory limit: intensifies or relaxes garbage collection process.
\end{itemize}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{OverallFramework.png}
  \caption{Overall project diagram detailed.}
\end{figure}
\hspace*{3em} In distributed systems a high per node multi-programming degree translates to high availability. This kind of environment also has potential to behave in an elastic way, making more resources available when the load increases and reducing the utilised resources when it diminishes. This means that our framework would have a greater impact when applied to a cluster of computers running JavaScript applications rather than a single computer.\\
\hspace*{3em} In order to adapt to this scenario the interaction between the V8 instances and the manager is done through the network, using TCP/IP. This allows the manager process to reside on any machine in a network and coordinate the memory usage of all the V8 instances running within the cluster. This makes the framework very adaptable to various use scenarios. For example: if the frameworks is to be used on a single computer it becomes a special case of the general model, a cluster with one node.
\\\\
\hspace*{3em} A \textbf{JSON} protocol is used to represent the commands and updates that are exchanged by the V8 instances and manager process. JSON is a good format option as it allows easy extension of the protocol schema, by simply adding additional keys the the concerned entities.
\begin{lstlisting}[language=json,firstnumber=1]
{
  "global":{"action":"","error":"", ... },
  "TotalIsolates":Integer,
  "isolates":{
    "1":{ "action":"","error":"", "heap":Integer,"throughput":Float,... },
    "2":{...}
    ...
  }
}
\end{lstlisting}
Here are the possible values that the \textbf{action} fields can have:\\\\
\begin{tabular}{  l  l  l  l  }
  Action & Global & Per Isolate & Description \\
\hline
  status & Yes & Yes & Isolate status request packet\\
  update & Yes & Yes & Isolate update response packet\\
  set\_heap\_size & No & Yes & Sets the heap size threshold over which the GC should intensify\\
  set\_max\_heap\_size & No & Yes & Sets the absolute maximum size the isolate can have\\
  terminated & Yes & Yes & V8 notifies the manager that one of its isolates has finished execution\\
\hline
\end{tabular}
\section{V8}
\hspace*{3em} The V8 virtual machine is based on isolated execution environments, each application runs in an isolated environment without the possibility of accessing resources owned by other applications running within the same V8 process. These isolation environments are called \textbf{isolates}. In essence, each isolate is an instance of the V8 virtual machine, having its own \textbf{heap space}, \textbf{garbage collector} and \textbf{compiler}. Only one thread can access an isolate at a time in order for the isolation to be maintained. 

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{V8Internals.png}
  \caption{V8 Internal Architecture.}
\end{figure}

A \textbf{context} defines a script execution environment by defining an object in an isolate's heap as a global object. Therefore, many contexts can exist in a given isolate and can also share any of their objects easily.
\begin{lstlisting}[style=htmlcssjs]
 <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/libs/jquery/jquery-1.7.2.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/libs/jquery/jquery-ui.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/video/new/jwplayer/jwplayer.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/scripts/bbq/jquery.ba-bbq.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/scripts/raccoon.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/jquery.flexslider.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/main.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/video.js"></script>
\end{lstlisting}
In the above extract from the HTML source of Glasgow University's website, each HTML script tag will cause the V8 to create a new context. Every script will be loaded in a different context but will share global variables.\\\\
The \textbf{heap} is divided into a set of spaces:
\begin{itemize}
\item \textbf{New Space} - Most objects are allocated here. This space is small and is designed to be garbage collected very quickly, independent of other spaces. 
\item \textbf{Old Space} - holds most objects that have pointers to other objects or contain raw data. Objects that survive the new space for a certain amount of time are moved here.  
\item \textbf{Code Space} - contains the instructions that comprise the compiled scripts
\item \textbf{Map Space} - Cells, Cell Properties and Maps !!-!!-!!-!!
\item \textbf{Large Object Space} - contains objects that are larger than the size limits of the other spaces. These objects are never moved by the garbage collector.
\end{itemize}
Each space is divided into a set of pages. A Page is a contiguous chunk of memory, allocated using operating system calls. Pages are always 1 MB in size and 1 MB aligned, except in large-object-space, where they may be larger. In addition to storing objects, pages also contain a header (with various flags and meta-data) and a marking bitmap (used to indicate which objects are live). Each page also has a slots buffer, allocated in separate memory, which forms a list of objects which may point to objects stored on the page.\cite{v8gctour}
\\\\
\textbf{Garbage collection} is comprised of two algorithms:
\begin{itemize}
\item \textbf{Scavenger} - is a copying garbage collection based on Cheney's algorithm. It only operates on the new space and occurs frequently.
\item \textbf{Mark Compact} - operates on the every other space except new space. It does not perform compaction on the large object space.
\end{itemize}

New-space is divided into two equal sized semi-spaces: to-space and from-space. Most allocations are made in to-space (with the exception of certain kinds of objects, such as executable Codes which are always allocated in old-space). When to-space becomes full, to-space and from-space are swapped. Then the live objects are copied out of the from-space either back into to-space or to old-space. Copying the objects into to-space also has the effect of compacting the space which improves locality of reference which, in turn, improves performance.%!
\\\\
Mark-Sweep \& Compact !!-!!-!!-!!
\\\\
\hspace*{3em} The garbage collection process incurs a certain performance cost. While actual memory \textbf{deallocation} can be done in \textbf{parallel} with the execution of JavaScript, the marking, moving and copying of live objects is much harder to parallelise. This is why garbage collection suspends the execution of hosted application. Since the new space is small, the frequent invocation of the Scavenger does greatly impact performance. The Mark-Compact on the other hand requires considerable pauses. To mitigate this, incremental marking has been implemented as well as a form of a deadline for each garbage collection pause. This way, the large pauses are divided into smaller ones causing unused memory to remain allocated for a longer period but improving the user perceived execution delay.

\subsection{Modifications}
\hspace*{3em} For the purpose of this project, the V8 engine had to be modified in order to communicate and comply with the manager process. This required both changes to existing code and additions of new code. Below is an overall diagram of the changes and additions:\\
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{V8Modifications.png}
  \caption{V8 modifications.}
\end{figure}\\
\begin{itemize}
\item \textbf{Heap} modifications allow setting a heap size limit and retrieving information about the memory usage (used memory, available memory and old space size). If the total heap size is larger than the set limit, the garbage collector will try to free as much memory needed to comply with it. Otherwise, when the heap size nears the set limit, garbage collection work intensifies to make sure it stays below the limit.
\item \textbf{Isolate} modification keep track of all the active isolates within the V8 process, measure execution and garbage collection times and calculate per isolate \textbf{throughput}. When a new isolate is crated, the tracker assigns it an numeric ID and adds it to a list of active isolates. When it finishes execution, its assigned ID is marked as free and the isolate is removed from the list.
\item A \textbf{Networking} client execution thread has been added to the V8 process for it to communicate with the manager. It is responsible with connecting to the manager, dividing the network data stream received from the manager into request packets, decoding them and performing the required actions and sending a response to the manager.
\item \textbf{Encoding} is nested, the first form is JSON which gets encoded to Base64. The latter uses a restricted set of characters to represent the payload which allows separating packets using ASCII characters that are not part of Base64. This allows the JSON payload to contain any symbols in its fields (even the packet separator character) without altering packet boundaries which simplifies the decoding process.
\item \textbf{Configuration} is done through a text file placed in the same folder as the V8 binary. This is meant to make the modified V8 more adaptable to other projects such as NodeJS and Chrome. If command line arguments were used in stead, they would have to be mirrored in both NodeJS and Chrome. The configuration file contains the IP address and port of the manager machine.
\end{itemize}
\section{Manager}
% High level description of the manager
\hspace*{3em} The main function of the \textbf{manager process} is to control the \textbf{memory limits} of each isolate. To do this, it needs to keep \textbf{track} of \textbf{active isolates}, \textbf{poll for status updates}, calculate new memory limits for every isolate and \textbf{give feedback} to the user on the status of the system. These functions have been divided into three main components: \textbf{Tracking}, \textbf{Management} and \textbf{Plotting}. The figure below is intended to be used as a reference when reading the remainder of this chapter.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1.0\textwidth]{PythonManager.png}
<<<<<<< HEAD
	\caption{Manager architecture.}
=======
  \caption{Manager architecture.}
>>>>>>> 643145c8b818e10beb9efd658802d679c6e97ce5
    \label{overalldesign}
\end{figure}
\subsection{Tracking} \label{Design:Tracking}
\hspace*{3em} This module is responsible with interacting and keeping track of the active isolates through the coordinated use of its components: \textbf{Registry Server}, \textbf{Communicator} and \textbf{Registry}. From the point of view of the framework, this module offers a means of communication with active isolates.
\\\\ %DESIGN_DECISION
\hspace*{3em} The registry maintains a \textbf{representation of the environment} managed by the application. Isolates are grouped together based on the V8 process they belong to and the machine they run on. The listing below shows the structure of the registry:
\begin{lstlisting}[language=json,firstnumber=1]
[{
  "id":"127.0.0.1",
  "v8s":[
    {"id":1,"isolates":[
      {"id":1,"heap":40542,"throughput":1.5},
      {"id":2,"heap":150241,"throughput":15.5},
    ...]
  },
    {"id":2,"isolates":[
    {"id":1,"heap":20541,"throughput":0.56},
        {"id":1,"heap":120443,"throughput":5.21},
    ...]
  },
  ...]
}, ... ]
\end{lstlisting}
In the case portrayed above, there are two V8 processes running on a the same machine as the manager process, each having two isolates. Using a hierarchical storage structure has the advantages of \textbf{minimal data redundancy}, ease of \textbf{extensibility} and \textbf{high topology fidelity}. The memory limits produced by the manager must not exceed the available memory of each machine, this requires knowing the provenience of each isolate. Each isolate is associated a local ID by its host V8, this is used to send memory limitations and other commands to the correct isolates. In order to send the commands to the right receiver, the active communications channel for each V8 process needs to be stored as well. If a non hierarchical structure such as a list were to be used, the aforementioned aspects would be more difficult to manage: the communication channel would be stored inside each isolate record adding one redundant field (many isolates can have the same host V8 process), mapping isolates to their host V8 processes and to their host machines would add even more redundant fields, determining which isolates belong to the same machine would become less efficient as it would require iterating through the entire list and mapping isolate updates coming from the network to their respective list records would require using a composite key in order to avoid iterating through the list. !!-!
\\\\
\hspace*{3em} The communicator represents an open channel to one V8 process. It handles encoding, decoding, sending and receiving messages to/from the V8. A communicator can represent at most one V8 instance at any given time.\\
\hspace*{3em} The Registry Server is responsible for servicing new connections from V8 instances to the manager. Once a new V8 engine connects to the manager, a record is added to the registry. A new communicator is created for the V8 and is added to its registry record. When a V8 finishes execution (or terminates abnormally), its communicator detects the closing of the channel and removes the corresponding V8 record from the registry. Since the communicator is stored in the V8 registry record, this will cause the communicator to cease to exist. 
\subsection{Management}
\hspace*{3em} The management module is responsible for \textbf{controlling the active isolates} by polling for updates, running a policy program that calculates memory limits, sending the calculated limits to the corresponding V8 processes and providing control over the framework to the user. The constituent components of this module are: the \textbf{Policy Executor}, \textbf{Policy Scripts} and a \textbf{Command Line Interface}.
\\\\
\hspace*{3em} The \textbf{Policy Scripts} are a collection of scripts that can be \textbf{loaded} into the manager framework \textbf{at run-time}. Only one such script can be running at any give time. A policy script receives a list of isolates and a maximum memory amount as input and \textbf{outputs the memory limits} for each of the provided isolates. All of the isolates in the input list run on the same machine, the maximum memory amount represents the maximum quantity of memory that JavaScript applications can use on the machine in question. This limitation reflects the fact that isolates running on one machine can not be allocated memory from multiple machines, therefore the total memory granted to the isolates can not be larger than the amount of physical memory available to the host machine !!-??-!!. It follows from this that the policy script needs to be run once for each machine managed by the framework. 
\\\\
\hspace*{3em} The \textbf{Policy Executor} regularly \textbf{polls} every V8 process present in the registry for status updates. These updates contain information such as: \textbf{in use heap size}, \textbf{total heap size}, available memory and \textbf{throughput}, which gets \textbf{copied into} the corresponding isolate record from  \textbf{the registry}. This information is used by the policy script to decide how much memory an isolate should have. The executor then groups all of the isolates based on their host machine and runs the current policy script for each machine.
\\\\
\hspace*{3em} The \textbf{command line interface} provides user access to the manager's functionality. Supported operations include changing the used policy script, changing the frequency of the status update polls, getting the latest status information of managed isolates, setting an isolate's memory limit, etc. This component is central to the evaluation as it allows the framework to test multiple policies without the overhead of restarting the whole infrastructure for every test, faulty policies can be detected during execution and swapped with correct ones, the full history of the status updates can be stored in files and examined post-execution or it can be plotted in real time on screen.
\\\\
\hspace*{3em} These three components come together to form the core of the framework by generating the memory limits for each manged isolate and allowing the user, the ultimate judge of the framework's effectiveness, to be part for the process and to observe its results in real-time. 
\subsection{Plotting}
\hspace*{3em} \textbf{Feedback} is crucial to evaluating the effectiveness of the policy used and, in turn, of the whole framework. This is why the manager application has a component dedicated to \textbf{gathering every status update} received by the registry and plotting a selected set of values on screen. Each full screen of plot history is saved in a PNG file, while the full history of the isolate's selected status values is saved to a CSV file for post-execution analysis. This module is comprised of three components: \textbf{Plotter}, \textbf{Plot Server}, \textbf{Plotting Service}.
\\\\
\hspace*{3em}  The \textbf{plotter} has the sole responsibility of receiving plot data, drawing it on screen and saving it to a file. It is modeled as a separate process from the manager framework. Plotters are started on demand, depending on how many isolates are being managed, each one represents a single isolate. 
\\\\
\hspace*{3em}  The \textbf{plotting service} is responsible with mapping a plot stream to one plotter process. A plot stream is comprised of the stream of status updates concerning one particular isolate. This service is responsible with detecting new streams, starting plotter processes for them and sending the plot data to the correct plotter processes. When a stream ends, because there is considerable overhead for creating a new process (and a new graphical window for drawing the plot), the plotting service keeps its corresponding plotter process in an idle state until a new stream is detected.
\\\\
\hspace*{3em} The \textbf{plotting server} has a function very similar to the registry server discussed in section 4.3.1. It starts plotter processes, when requested by the plotting service, and waits for them to connect in order to mark them as idle(ready to plot). The plotter processes are kept in a stack until they are needed by the plotting service. When a stream ends, the plotting service returns the plotter process to the server's stack in order to wait for a new stream to start.
\\\\
\hspace*{3em} The approach of having multiple separate processes handling plotting was chosen over having one process updating multiple windows (or multiple subplots) mainly because the library used is not designed to manage multiple independent plot windows but also to increase flexibility. With this model some plots (or all of them) could be offloaded to a different machine. !!-??  
\section{Software Engineering}
Separation of concerns\\
Extensibility - properties can be added and removed\\
Modularisation in Folders with closely related code\\
Pluggability of policy - loose coupling\\
!!-!!-!!-!!
\newpage
\chapter{Implementation}
CHAPTER DESCRIPTION
\section{Overview}
\hspace*{3em} There are three may areas of the implementation
\begin{itemize}
\item Building the manager framework
\item Changing the V8 engine to allow it to be controlled by the framework
\item Building a V8 wrapper responsible with running JavaScript applications specified through command line arguments.
\end{itemize}
\hspace*{3em} A V8 isolate, by itself, is simply an execution environment, the specific script that needs to run has to be \textbf{compiled} and \textbf{loaded} into the isolate. This is done using the functions provided by said isolate. The \textbf{V8 wrapper} is a C++ application that creates one isolate, takes in a list of scripts, compiles them and runs them inside the isolate. It also takes a size expressed in megabytes and sets it as the maximum heap size of the isolate.
\\\\
\hspace*{3em} The \textbf{Google V8} engine is implemented in \textbf{C++}, amounting to 800,000+ lines of code. Changing it requires using the same language which does not allow much freedom of choice. However, the management framework is an independent process and can be implemented in any language. \textbf{Python} was chosen for this task for the following reasons:
\begin{itemize}
\item It is a high level language with a small code footprint
\item It is interpreted, which allows loading and executing code at run-time and also eliminates compilation waiting time. (The V8 wrapper, despite its small size, has a compilation delay of around 30 seconds)
\item It has extended support from its community with plenty of useful libraries available
\item Has built in support for most of the required constructs to build the management framework including popular data representation protocols such as Base64 and JSON.
\end{itemize}
\hspace*{3em} The changes carried out on the V8 engine involve allowing the heap size limit to be set at run-time as well as adding a network client responsible with connecting to the manager framework, applying the limits (or other commands) received from the manager and replying with status updates.
\\\\
\hspace*{3em} JSON was used for the communication protocol employed by the V8 instances and the management framework because it is human readable and supports nesting well. This is appropriate as the project aims for correctness rather than performance at this stage. Human readability allows for easy debugging while nesting support contributes to a clear representation of the environment topology.
\\\\
\hspace*{3em} The manager framework implementation uses built in python functions for JSON and Base64 encoding and decoding while the V8 changes use custom built Base64 functions and a third party JSON C++ library.
\section{V8 Client}
\hspace*{3em} The main responsibility of V8 is to run scripts as efficiently as possible. Any form of \textbf{computation} not related to executing the scripts would be perceived as \textbf{overhead} by the user. Garbage collection is one example of such additional computation as it is responsible with freeing memory rather than advancing the execution of the hosted scripts. For this reason, collection pauses are kept as short and far apart as possible. The \textbf{changes} added to V8 for the purpose of this project are not related to script execution which would classify them as computational overhead. For this reason, the changes were designed to have a \textbf{minimal performance impact}. This was achieved through a set of implementation decisions detailed below.

\subsection{Enforcing Limits}
\hspace*{3em} By design, each V8 isolate is configured with memory limits for its old space and new space when the isolate is created.
\begin{lstlisting}[language=cpp]
Isolate::CreateParams create_params;
create_params.constraints.set_max_old_space_size(max_heap);
create_params.constraints.set_max_semi_space_size(16);

Isolate* isolate = Isolate::New(create_params);
\end{lstlisting}
\hspace*{3em} The memory spaces constituting the heap are divided into \textbf{1 megabyte pages}. The two functions from the listing above take in values representing a number of megabytes. Since this is an extract from the V8 wrapper, the new space size is set to 16 megabytes, while the old space is set to the value of the first command line argument. This also determines the level of \textbf{granularity} that the manager framework can use to determine memory limits. According to the creators of V8, the maximum amount of memory an isolate can use is \textbf{1 gigabyte}. Any value above that would cause the garbage collector to behave erratically.\cite{v8sizebug} This gives the manager a \textbf{range of 1000} possible memory limit values enforceable by V8.
\\\\
\hspace*{3em} When a new isolate is created, the value of the argument passed to set\_max\_old\_space\_size() method is copied into the \textit{max\_old\_generation\_size\_} member variable of the heap class. This class models the heap of a single isolate, it holds pointers to all of the spaces comprising the heap and contains member methods that control garbage collection. The heap is allowed to expand up to the limit set at isolate creation. Normally this limit is larger than the initial heap size. However, if the limit is smaller than the current heap size, the garbage collector will strive to free as much memory as possible in order to comply with it. This enables enforcing heap memory limits at run-time by simply updating the  \textit{max\_old\_generation\_size\_} variable. To do so, a setter method called \textit{setMaxOldGenerationSize(int)} has been added to the heap class.  %CONCURRENCY?
\\\\
\hspace*{3em} Another way of enforcing memory limits at run-time would be to modify the garbage collector so that it runs until the size of the heap becomes smaller than the limit or until no more memory can be freed. This is not a preferable solution because it would override the optimisations employed by the designers of V8 by performing long garbage collection runs whenever the limit becomes lower than the current heap size, making them much more obvious to the user. This approach also adds additional computation to the garbage collection process when compared to a simple copy operation employed by the setter function mentioned above.
\subsection{Measuring Throughput}
\hspace*{3em} An \textbf{important metric} that needs to be calculated and reported back to the manager is the application \textbf{throughput}:
\begin{equation}
throughput = \frac{\textit{Execution interval}}{\textit{Garbage Collection interval}}
\end{equation}
\hspace*{3em} This reflects how much time is spent executing JavaScript code versus the time spent performing garbage collection. Therefore, a throughput of 1 means that V8 spends an equal amount of time executing the application and collecting garbage. A value greater than one means more time is spent executing the application while a value lower than 1 means that more time is spent performing garbage collection. The latter implies that the application is somewhat "struggling" to execute as more work is put into freeing memory rather than execution. Ideally, more time should be spent executing the application than collecting garbage. This is what V8 normally optimises for by keeping garbage collection pauses small and far apart. A high throughput implies reduced jank observed by the user in the browser.
\\\\
\hspace*{3em} \textbf{Throughput is calculated} by measuring the length of the \textbf{garbage collection pauses} and the \textbf{intervals between the pauses}. The V8 application programming interface (API) provides callback functionality for the garbage collection start and end on a per isolate basis. V8 defines the start of the garbage collection as the prologue and the end as the epilogue, hence the callback functions are named \textit{gcPrologue()} and \textit{gcEpilogue()}. The two durations, exeuction time and collection time, are obtained by subtracting the timestamps captured by gcPrologue() and gcEpilogue(). These are stored in isolate member variables called \textit{timePrologue} and \textit{timeEpilogue} respectively. 
\begin{equation}
\textit{ExecutionDuration} = \textit{timePrologue} - \textit{timeEpilogue}
\end{equation}
\begin{equation}
\textit{CollectionDuration} = \textit{timeEpilogue} - \textit{timePrologue}
\end{equation}
Execution duration is called when gcEpilogue() runs because the value of timeEpilogue was captured when the previous garbage collection pause ended, making it the starting time of the current execution interval. Collection duration is calculated when gcEpilogue() runs because the value of timeEpilogue is updated with the current garbage collection end time, making the difference between the two equivalent to the duration of the collection process. 
\\\\
\hspace*{3em} The above calculations are accurate with the exception of the moment when the first gcPrologue() is called. At this point, timeEpilogue is not initialized, making the value of ExecutionDuration invalid. To mend this, timeEpilogue is initialized with the current time-stamp when the isolate is created. Below is a listing of V8 modifications that perform the throughput calculation:
\begin{lstlisting}[language=cpp]
bool Isolate::Init(Deserializer* des) {
  ...
  // initialise GC callbacks
  timeEpilogue = high_resolution_clock::now();
  this->heap()->AddGCPrologueCallback(staticGCPrologue,GCType::kGCTypeAll,true);
  this->heap()->AddGCEpilogueCallback(staticGCEpilogue,GCType::kGCTypeAll,true);

  return true;
}

void Isolate::gcPrologue(GCType type, GCCallbackFlags flags){
  timePrologue = high_resolution_clock::now();
  auto duration = duration_cast<microseconds>( timePrologue - timeEpilogue ).count();
  executionTimes[gcIndex] = (int) duration;
}

void Isolate::gcEpilogue(GCType type, GCCallbackFlags flags){
  timeEpilogue = high_resolution_clock::now();
  auto duration = duration_cast<microseconds>( timeEpilogue - timePrologue ).count();
  gcTimes[gcIndex] = (int) duration;
  
  if(executionTimes[gcIndex] < 0)
    executionTimes[gcIndex] = gcTimes[gcIndex];
  
  calcThroughput();  
  gcIndex ++;
  gcIndex %= sampleLength;
}

void Isolate::calcThroughput(){
  long long divBy = gcTimes[gcIndex];
  double tp = 100;
  
  if(divBy != 0)
    tp = ((double)executionTimes[gcIndex])/divBy;

  lastThroughput = (tp > 100)?100:tp;
}
\end{lstlisting}
\hspace*{3em} In the above listing, the time-stamps are stored in vectors because \textbf{initially} the V8 modifications were intended to \textbf{return average values} of the throughput. This approach was \textbf{abandoned} because the \textbf{manager framework} is able to poll V8 instances at configurable frequencies, and also because it \textbf{better suited} to \textbf{decide} what \textbf{alterations} should be performed on the status information in order \textbf{to better reflect} the \textbf{state of the isolate}. This way, the V8 only responsible with returning raw status data, which in turn \textbf{minimises} the \textbf{computational overhead} added by the changes. 
\subsection{Compiling Status Information}
\hspace*{3em} The \textbf{manager} is designed to \textbf{poll} all the tracked V8 instances for \textbf{status updates}. For every isolate belonging to a V8, the manager will send a status \textbf{update request}. Upon receipt of the request, the host V8 process must \textbf{collect status information} for the specified isolate and send it back to the manager. This operation must not be costly in terms of \textbf{computation} as it would \textbf{impact} the \textbf{performance} of the running scripts. This was achieved by adding member variable \textbf{accessor methods} that sum up a small number of values or simply return one value. Some such functions rely on underlying V8 accessor methods which had to be \textbf{carefully selected} because some traverse the pages comprising the heap in order to return the size while others return the value of a member variable. The methods that traverse the heap were avoided because of the considerable performance cost they incur since the aim of the project is to maintain high performance while adding global allocation resource supervision. To illustrate the performance cost of traversing the heap in order to retrieve its size, I have used the D8 (a version of V8 used for debugging JavaScript applications). This program not only retrieves the size of the heap at every garbage collection event, but also traverses it in order to map the objects that are live at that point in time. Below is a listing of the accessor functions added to the isolate class:
\begin{lstlisting}[language=cpp]
long long Isolate::getHeapSize(){
  return (long long) (heap_.old_space() ->Size() + heap_.map_space() ->Size() +
                      heap_.new_space() ->Size() + heap_.lo_space()  ->Size() +
                      heap_.code_space()->Size()
  );
}

long long Isolate::getMemoryFootprint(){
  return (long long)(heap_.old_space() ->Capacity() + heap_.map_space() ->Capacity() +
                     heap_.new_space() ->Capacity() + heap_.code_space()->Capacity() +
                     heap_.lo_space()  ->Size()
  );
}

long long Isolate::getAvailableHeapSize(){
  return (long long)(heap_.old_space() ->Available() + heap_.map_space() ->Available() +
                     heap_.new_space() ->Available() + heap_.code_space()->Available()
  );
}

double Isolate::getThroughput(){
  return lastThroughput;
}
\end{lstlisting}
\subsection{Isolate Tracking}
\hspace*{3em} \textbf{V8} is meant to be \textbf{embedded in larger projects} that employ its functionality. The host project would decide what scripts to run and used V8 to compile and execute them. The isolates would be created outside of the V8 source code as it is simply an engine offering functionality to its host program. Because of this, there there is \textbf{no functionality} that \textbf{tracks} the number of \textbf{active isolates} in V8. The manager framework needs a way to identify and track the active isolates belonging to each V8 process. This can be done either in the V8 source code or in the program it is embedded in (V8 wrapper in the case of this project). The latter involves much less overall V8 code changes but does makes it very hard to adopt modified engine in a different project that makes use of V8, such as NodeJS and Chrome. This is why isolate tracking was added to the V8 source code.
\\\\
\hspace*{3em} Upon \textbf{creation}, an isolates is assigned a \textbf{identification number} and a \textbf{pointer} to the isolate object is stored in an array. This number is used by the management framework to \textbf{address the isolate} it wants to control. The V8 network client(detailed below) uses the identification number of the isolate to retrieve the stored object pointer and call the appropriate member functions in order to carry out the command received from the manager. Upon \textbf{disposal} of the isolate, its \textbf{identification number} becomes \textbf{free} and can be used to address another new isolate and the \textbf{pointer} is \textbf{removed} from the array. Below are code extracts demonstrating:
\begin{lstlisting}[language=cpp]
int ISOLATE_INDEX = 1;
std::map<int,Isolate *> allIsolates;
std::list<int> freeIDs;
pthread_mutex_t count_mutex = PTHREAD_MUTEX_INITIALIZER;
...
Isolate::Isolate(bool enable_serializer){ 
  //constructor call modified to add isolate pointer to map
  ...
  Isolate::addNewIsolate(this);
}
Isolate::~Isolate() {
  //destructor modified to delete pointer to isolate
  Isolate::removeIsolate(this);
  ...
}
void Isolate::addNewIsolate(Isolate * i){
  pthread_mutex_lock(&count_mutex);

  int id = 0;  
  if(freeIDs.empty()){
    id = ISOLATE_INDEX++;
  } else {
    id = freeIDs.front();
    freeIDs.pop_front();
  }

  i->setIsolateId(id);
  allIsolates[id] = i;

  pthread_mutex_unlock(&count_mutex);
}

void Isolate::removeIsolate(Isolate *i){
  pthread_mutex_lock(&count_mutex);
  
  int id = i->getIsolateId();
  if(allIsolates.erase(id))
    freeIDs.push_front(id);
  
  pthread_mutex_unlock(&count_mutex);
}
\end{lstlisting}

\subsection{Client}
\hspace*{3em} A \textbf{TCP/IP client} was added as a separate execution thread to the V8 process. Its purpose is to continuously attempt to \textbf{connect} to the \textbf{manager} framework until a successful connection is established, after which it \textbf{waits for commands}, \textbf{applies} then by calling the appropriate V8 API functions and \textbf{responds} with status updates. A \textbf{separate thread} was used in order to allow the \textbf{isolates} to run \textbf{undisturbed} and unaware of the existence of the server. This way, the status updates reflect the \textbf{instantaneous state} of the isolate at the moment when the command arrived. Before starting the client, a file called \textbf{V8RemoteControlConfig.txt} containing the manager \textbf{IP} address and \textbf{port} is parsed. The provided IP and port numbers are used to connect to the manager. If this file does not exist, the server reverts to the \textbf{localhost} address 127.0.0.1 with port 15004 assuming the manager is located on the local machine. A \textbf{file} was used to configure the destination IP and port rather than \textbf{command line arguments}, because in the future, this extension might be included in applications like NodeJS, NWJS and Chrome which would require adding the \textbf{additional command line options} to each of these three projects' source codes. A modified build of the \textbf{Chrome} web browser was created for the purpose of this project. Having the V8 client configure itself using a file eliminated the need to change any additional Chrome specific code, which made the integration of the modified V8 simply a task of replacing the modified files and slightly changing the build procedure to include the new files. %easy peasy I figured out how ninja describes the build process 
\subsection{Communication Protocol}
\hspace*{3em} The last set of changes added to the V8 project implement the \textbf{communication protocol}, including \textbf{encoding} and \textbf{decoding} it. The protocol, described at \ref{Design:Tracking}, is based on objects called \textbf{actions}. They can be either \textbf{requests} or \textbf{responses} and can refer to either the \textbf{V8 process} itself (global request or response) or to one of its \textbf{isolates} (local request or response). The action object contains the name of the command to be applied (or the kind of response being returned) and a set of fields containing the required information. A request would be comprised of one global action object and an array of local action objects. The number of local action objects corresponds to the number of isolates the V8 is running. Below is a diagram of the classes that model a protocol message.     
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.80\textwidth]{ProtocolClasses.png}
<<<<<<< HEAD
	\caption{Protocol entities grouped into classes.}
=======
  \caption{Protocol entities grouped into classes.}
>>>>>>> 643145c8b818e10beb9efd658802d679c6e97ce5
\end{figure}
\\
\hspace*{3em} The \textbf{details class} is comprised of public fields representing every possible piece of information that can be put in an action object along with functions used to build the object from a JSON string and to convert it to such a string. Each Action class is comprised of a \textbf{name field}, used to determine what request or response it represents, a \textbf{details object} for the additional information and an \textbf{error object}. The latter is used to represent any kind of error encountered while performing the action. The \textbf{command class} contains an action object representing the \textbf{global action}, array of action objects representing the \textbf{isolate level actions} and an \textbf{error object}. The latter is used to represent errors at a command level. If the array of actions was longer than the array of isolate object pointers, meaning that the manager sent limits for more isolates than are actually active, would qualify as a local error and will be represented in the last action object of the actions array from the command object. If the message received from the network could not be decoded, the global error object of the command will be filled in with information about the error and the execution of the command will be aborted.
\\\\
\hspace*{3em} A \textbf{third party library} called \textbf{JsonCpp} was added to V8 in order to handle encoding and decoding JSON. The V8 engine does support JSON, since it stands for Java Script Object Notation, but it is implemented in JavaScript. This means that in order to encode or decode JSON, JavaScript code would have to be run in one of the available isolates or in its own one. This would cause framework related code to compete with hosted application code for execution time. The third party library code will run in the separate thread of the network client and therefore would not directly impact the execution time of the hosted applications. JsonCpp parses JSON strings and produces \textit{Json::Value} objects. These are then passed to the appropriate instances of the protocol classes in order to load the values into the appropriate member variables. Every class comprising the protocol implementation with the exception of the Command class has a \textit{void deserialise(Json::Value obj);} method which loads values from a JSON object. Conversely, a \textit{void serialise(Json::Value \&obj);} method does the opposite operation when the protocol message needs to be encoded in order to be sent to the manager. The Command class is responsible with performing encoding and decoding from and to string, it also has the two aforementioned methods but in the following format: \textit{std::string serialise();} and \textit{void deserialise(std::string);}. This makes the decoding of a JSON string received over the network from the manager as simple as calling one function: \textbf{command.deserialise(string);}.
\\\\
\hspace*{3em} Base64 encoding and decoding procedures were added to the V8 project for the same reason the built in methods were not used to parsing JSON. Handling messages from the manager requires reading data from the network in a string until the separator is read, instantiating a Command object, decoding the string received over the network using Base64 and then passing it to \textit{command.deserialise();}. Similarly, sending a response to the manager requires modifying the command object to reflect the state of the last performed action, calling \textit{command.serialise()}, base64 encoding the resulting string, appending the separator and sending it over the network.
\section{Manager}
\hspace*{3em} The role of the manager framework is to keep track of active isolates, control their memory usage by applying a management policy, give feedback on the status of each isolate to the user and allow the user to control the framework. There are three main modules comprising the framework: \textbf{Tracking}, \textbf{Management} and \textbf{Plotting}. These are divided further into more specialised scripts:
\dirtree{%
.1 \textbf{Management}.
.2 \textbf{Communication}.
.3 \text{server.py}.
.3 \text{communicator.py}.
.3 \text{requestBuilder.py}.
.2 \text{monitor.py}.
.2 \text{policy.py}.
.2 \text{cli.py}.
.1 \textbf{Plotter}.
.2 \text{IpcPlotWrapper.py}.
.2 \text{plotter.py}.
.1 \textbf{PlotFacility}.
.2 \text{PlotServer.py}.
.2 \text{PlotService.py}.
.1 \text{main.py}.
}
\hspace*{3em} Tracking and Management share a \textbf{core component}: the \textbf{registry} (implemented in monitor.py). Tracking accepts connections from V8 instances, creates and associates a communicator instance with each newly open connection and updates the registry to reflect the changes. Any message received by a communicator from its associated V8 updates the corresponding registry record. When a connection is closed, its corresponding communicator automatically updates the registry. The management module scans the registry for active isolates and sends them update requests, it also groups isolates by the machine they belong to and sends them heap limit values. Because of the dependence of the management module on the tracking, the latter has been embedded into management as a sub-module named Communication. However, the plotting module has been divided in two: Plotter and PlotFacility in order to reflect the underlying architecture. The external plotter process from \cref{overalldesign} was implemented in the Plotter module as a standalone application while the remaining functionality was implemented by the scripts in PlotFacility. 
%more info on how they get wired
\subsection{Tracking}
\hspace*{3em} The \textbf{registry} keeps track of the state of the monitored environment. It uses a hierarchical model implemented using a python dictionary:
\dirtree{%
.1 machines.
.2 \text{Machine\_1}.
.3 \text{V8\_1}.
.4 \text{Isolate\_1}.
.4 \text{Isolate\_2}.
.3 \text{V8\_2}.
.4 \text{Isolate\_1}.
.2 \text{Machine\_2}.
.3 \text{V8\_1}.
.4 \text{Isolate\_1}.
}
The dictionary nodes representing each of the types of nodes show above (machine, v8, isolate) have the following structure: 
\begin{lstlisting}[language=python]
machine = {"FreeList":list(),"v8s":dict(),"id":"0", "memoryLimit":self.newMachineMemLimit}
v8      = {"FreeList":list(),"isolates":dict(),"id":0}
isolate = {"id":0,"created":time.time()}
\end{lstlisting}
\hspace*{3em} When a new machine is added to the registry, its IP address is used as a value for the id field. New V8 and Isolate instances are automatically assigned identification numbers which are unique within the context of the parent node. V8 ids are unique within the context of their host machine, while Isolate ids are unique within the context of their host V8 processes. The IDs are chosen by finding the smallest number not in used by another instance within the same context. When an Isolate instance is removed, its ID is stored in the free list of its parent V8. When a V8 instance is removed, its ID is stored in the free list of its host machine. This is how free IDs are being managed.
\\\\
\hspace*{3em} A mutex lock is used to ensure concurrent changes are carried out safely. Operations that are used by external components such as the communicator and policy executor are considered potentially unsafe and therefore the mutex is used to ensure safety. Functions meant to be called internally do not use the mutex in order to optimise execution speed since locking and unlocking mutexes adds considerable overhead.
\\\\
\hspace*{3em} The \textbf{server} runs in a separate thread that has the responsibility of accepting incoming TCP/IP connections, creating a new communicator object for each new connection and adding the machine that has initiated the connection to the registry if it was not added already.
\begin{lstlisting}[language=python]
soc,addr = self.soc.accept()
addr = str(addr[0])
machineId = self.monitor.getMachine(addr);
if machineId == 0:
<<<<<<< HEAD
	machineId = self.monitor.addMachine(addr); 
else:
	machineId = machineId["id"];
=======
  machineId = self.monitor.addMachine(addr); 
else:
  machineId = machineId["id"];
>>>>>>> 643145c8b818e10beb9efd658802d679c6e97ce5
communicator(soc,self.monitor,machineId,self.monitor.update);
\end{lstlisting}
\hspace*{3em} \textbf{Communicators} represent a communication channel to a single V8 instance. Hence, they require a reference to the registry in order to add a new V8 record to it. This reference is passed at the constructor call (self.monitor from the above listing). A new communicator creates a separate thread that listens for messages from the remote V8. As soon as a message arrives a method from the registry's interface is called in order to directly update the relevant record. A send function is also part of the communicator interface. This allows other components to send messages to the V8 instances managed by the system. Each registry record of a V8 has a reference to its associated communicator in order for other components to be able to contact the V8 process. Getting a V8's communicator requires calling a registry method and providing a machine id and a V8 id: \textit{getV8Comm(machineId,v8Id)}.
%requestbuilder?

\subsection{Management}
\hspace*{3em} The center piece of the management module is the \textbf{policy executor} (policy.py). This script is responsible with gathering status updates from every managed isolate and applying a selected policy to the groups of isolates belonging to each machine connected to the manager. It also validates the output produced by the policy script and implements functionality for loading a policy script at run-time as well as changing the polling frequency. This functionality is exposed to the command line module to enable the user to change the policy and polling frequency at run time. Below is an outline of the policy executor methods:
\begin{lstlisting}[language=python]
class Policy:
    def __init__(self,monitor,frequency,cfgfile)
    def ldConfig(self,fileN)
    def changeSamplingFrequency(self,hz)
    def __loadModule(self,filepath)
    def loadPolicy(self,policyName)
    def logPolicyInfo(self,name,msg)
    def validateSuggestions(self,suggestions,maxMachineMemory)
    def run(self)
\end{lstlisting}
\hspace*{3em} Because policy implementations are intended to be modular and interchangeable, in order to allow the system to load policies at run-time, a standard for implementing one has been outlined. A policy script must implement every method below in order to be successfully loaded and used by the framework. 
\begin{itemize}
\item \textit{init(context)} - called when the policy is applied for the first time to the isolates of a machine.
\item \textit{calculate(totalAvailableMemory,isolates,context)} - this method computes the memory limits. It is called at the same frequency as the status polling. The input parameters are a maximum memory limit, a list of isolates with status information and the return value is a list of the memory limits.
\item \textit{name()} - returns a string containing the name of the policy
\item \textit{stats()} - if the policy maintains any status information, returns a string with that information.
\end{itemize}
\hspace*{3em} The \textbf{command line interface} (cli.py) allows the user to control the framework through the use of text commands. A total of 31 commands are available with functions ranging from simply listing the connected isolates, changing the polling frequency, listing available policy scripts to changing the currently running policy script, manually sending memory limits to isolates, changing the total memory limits on machines and determining whether the status information is plotted live on the screen or simply saved to a file for post execution analysis. A listing of the full list of commands can be found in \cref{allcommands}.Below is listing of the command line showing the connected
isolates:
\begin{lstlisting}
[ MACHINE_127.0.0.1 ]  400 MB
{ V8_1 } 1 MB
  0:0:33.0 (1) available:1048576 average:0 maxFootPrint:1048586 avindex:0 footPrint:1048586 throughput:1.0 v8Id:1 heap:1048576 hardHeapLimit:209715200.0 pMark:True 
_____________________________________________

 V8_2   1 MB
  0:0:6.0 (1) available:1048576 average:0 maxFootPrint:1048586 avindex:0 footPrint:1048586 throughput:1.0 v8Id:2 heap:1048576 hardHeapLimit:209715200.0 pMark:True 
_____________________________________________
\end{lstlisting}
\hspace*{3em} The [] brackets denote the current machine and the \{\} brackets denote the current V8 that the command line is pointing at. Commands regarding isolates go to the V8 highlighted above. The CLI is \textbf{versatile} enough to be used to \textbf{configure the environment}. This is done using text configuration files which contain commands (one per line). These are applied sequentially when the policy executor object initialises. Configuration files are found in the configuration folder. Here's an example of how to start the manager with a configuration file other than default.txt: \textbf{./main.py config=fullFeatures.txt} 

\subsection{Plotting}
<<<<<<< HEAD
\hspace*{3em} The main \textbf{feedback} mechanism for the frameworks is \textbf{plotting status information}, such as heap size, throughput, imposed memory limit, received from isolates. This is done using the python matplotlib library \cite{matplotlib}. The framework creates a plot window for each isolate that is being controlled and sends the isolate status fields to the corresponding windows as soon as they arrive from the host V8 instances. This is done through registry code: as soon as an update comes on the network, after the registry has been updated, the information is also set to the plotting facility.
\\\\
\hspace*{3em} Plotting involves associating each isolate with a plot window, sending the information concerning an isolate to the correct window and plotting it. To handle this, the plotting module has been split in two sub-modules:
\begin{itemize}
\item \textbf{Plot Facility} - responsible with creating new plotter windows when needed, associating isolates with plotter windows and sending status information to the correct window. 
\item \textbf{Plotter} - is a separate process instantiated by the plot facility on demand, responsible with receiving plot data and drawing it on the screen.
\end{itemize}
\hspace*{3em} The plotter also saves the data it receives in two types of files: a full history of the status information stored in a CSV file and a sequence of PNG files. The latter are captured when the plot data fills the entire surface of the window or when the isolate finishes execution.
\\\\
\hspace*{3em} \textbf{Plotting} while the framework controls isolates comes with \textbf{considerable overhead}. Operations such as redrawing the lines on the screen as well as starting new plotter processes (which start plotting windows) are quire costly in terms of computation and therefore need to be handled with care. In order to minimise the overhead brought by such operations a number of \textbf{optimisations} have been implemented:
\begin{itemize}
\item \textbf{Reusing Plot Windows} - when an isolate finishes execution its corresponding plotter window is put in an idle state. Idle windows are stored in a stack by the Plot Facility to be reused when new isolates begin execution. This way some of the overhead of creating new windows is circumvented. 

\item \textbf{Skipping Render Steps} - by default, the policy executor asks for status updates at a frequency of 10Hz. Receiving data at high frequency causes the cause the plot library to do a large amount of computation because it has to redraw the whole graph surface. This causes it to fail to show an up-to-date view of the isolate's state, because previous plotting operations have not yet finished before the availability of new data. To mitigate this, the plotter is configured with a target time interval between plot updates. It then measures the time taken to plot updates. If this time is larger than the configured interval then some of the upcoming updates would not be drawn on screen, creating a skip-ahead effect that ensures the plot window does not lag behind.
\begin{equation}
	\textit{NumberOfUpdatesToSkip} = floor(\frac{\textit{DrawDuration}}{\textit{ConfiguredInterval}})
\end{equation}

\item \textbf{Post Execution Analysis} - Live updating can be costly even with the above optimisations. Depending on the nature of the experiments being carried out, live plotting can be deactivated in favour of saving the full plot history of one isolate in a CSV file. The data in this file can be plotted after execution has finished. This completely eliminates the overhead of redrawing plot lines as well as creating graphical plot windows. 
\end{itemize}

\subsection{Data Flow}
\hspace*{3em} Data flows through the system from the Tracker through Management to Plotting. The policy executor will send out status update requests for each tracked V8 through its associated communicator then it will group isolates belonging to the same machine, calculate memory limits for them and send them out through their host V8 communicators. Blow is an diagram illustrating the flow of data through the framework:
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1.0\textwidth]{DataFlow.png}
	\caption{Flow of data through the framework.}
    \label{dataflow}
\end{figure}
\\\\
\hspace*{3em} The main priority of the manager is to calculate memory limits and send them to the isolates quickly. This is why status polling and the calculating the memory limit happen on the same thread (policy executor thread). Updates from the network are handled by the execution thread of the receiving communicator. This thread handles updating the registry and also sends the update to the plotting facility if this feature is enabled. Because updates come at a relatively high frequency the amount of computation needed to handle one request needs to be kept relatively small. For this reason, the functionality illustrated in \cref{dataflow} (bottom right) has been put in a separate thread. The communicator thread simply adds the new update to a queue to be processes by the plot facility thread. This ensures the communicator handler only carries out critical operations such as updating the registry. Safe operations is ensured by mutex locks implemented by the registry and the plot facility.
\\\\
\hspace*{3em} The manager framework is mean to run for prolonged amounts of time and process high volumes of data. Debugging the application becomes difficult if all error messages are passed to process standard output. \textbf{Logging} has been added to the system in order to keep a record of the framework status and errors encountered. Each module discussed in this chapter should maintain a log of its own, but due to time constraints logging has been added only to the policy executor and plot facility modules. The policy executor log is key to debugging policy scripts as it is the file that stores the errors and warnings for the current policy script. Third party developers could create new such scripts and use the log to check if they exhibit correct behaviour.
=======
Plotting configuration - makes pictures of the whole graph history and CSV file with entire history
\subsection{Data Flow}
Locks and queues
Data Flow through framework
\\Logging + configurability
Amazing CLI - also enables configuration files applied before framework starts
Ability to change policy at runtime
>>>>>>> 643145c8b818e10beb9efd658802d679c6e97ce5
\section{Testing}
\hspace*{3em} Testing was facilitated by additional scripts that instantiate the components to be tested and call the relevant member functions. If any errors are encountered, this would indicate there is a flaw in the scrutinized component. Trace-backs will indicate where the problem originates, aiding the solving process. %implement an automated check for the registry structure and packet builder
\\\\
\hspace*{3em} The most critical part of the system is the registry.
\\\\
\hspace*{3em} Packetisation
\\\\
\hspace*{3em} Policy Testing - specify policy, auto load, manual input, replay collected data, collect results in file through pipe-ing
\\\\
\hspace*{3em} After the critical components have been tested, final step was to ensure that the manager framework worked as a whole and did indeed affect the amount of memory an isolate could utilise. To do this, the framework was started along with a V8 isolate running the binary tree benchmark. At different intervals of time memory limits were set, using the command line interface, and the memory utilisation was observed. The graph below shows the evolution of the heap size of an isolate controlled with the manager framework:
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1.0\textwidth]{ControlWorks.png}
  \caption{Controlling heap size.}
\end{figure}

\chapter{Evaluation}
CHAPTER DESCRIPTION\\
How isolates are mapped as individuals, what the gini is applied to.
Throughput, heap, footprint, limit, distance to limit.
\section{Equal Share Policy}
\begin{equation}
\textit{HardHeapLimit}_i = \textit{MaximumMemoryPerMachine} \times \frac{1}{\textit{NumberOfActiveIsolates}}
\end{equation}
\section{Inverse Throughput Policy}
\begin{equation}
\textit{Total Throughput} = \sum_{i=0}^{N} -\log_2(\frac{t_i}{1000})
\end{equation}
\begin{equation}
\textit{Hard Heap Limit}_i = \textit{MaximumMemoryPerMachine} \times \frac{-\log_2(\frac{t_i}{1000})}{\textit{Total Throughput}}
\end{equation}
\section{Robin Hood Policy}
Definitions: Isolate(h,a,t,L) h is the used heap memory, a is the unused heap memory, L is the maximum allowed heap size, t is the throughput. N is the total number of isolates running on a machine, P is the number of poor isolates, R is the number of rich isolates. 
\begin{equation}
\textit{Immediate Budget} = \textit{Total Allowed Memory} - \sum_{i=0}^{N}L_i
\end{equation}
\begin{equation}
Need_i     = Max(0,h_i \frac{-\log_2{t_i}}{2} - L_i)
\end{equation}
\begin{equation}
\textit{Total Need} = \sum_{i=0}^{P}Need_i
\end{equation}
\begin{equation}
\textit{OverflowNeed}     = Max(0,\textit{TotalNeed} - \textit{ImmediateBudget}) 
\end{equation}
\begin{equation}
\textit{AllocatableNeed}     = Max(0,\textit{TotalNeed} - \textit{OverflowNeed}) 
\end{equation}
\begin{equation}
\textit{StealAllowance} = Min(0.5,\frac{\textit{OverflowNeed}}{\sum_{i=0}^{R}L_i}) 
\end{equation}
\begin{equation}
\textit{AllocateAllowance} = \frac{\textit{AllocatableNeed}}{\textit{TotalNeed}} \times Min(1.0,\frac{\textit{AllocatableNeed}}{\textit{ImmediateBudget}}) 
\end{equation}
\begin{equation}
\textit{GiveAllowance} = \frac{\textit{OverflowNeed}}{\textit{TotalNeed}} \times Min(1.0,\frac{\textit{OverflowNeed}}{\textit{TotalStolen}}) 
\end{equation}
\begin{equation}
Steal_i = \textit{StealAllowance} \times L_i 
\end{equation}
\begin{equation}
Give_i = (\textit{GiveAllowance} + \textit{AllocateAllowance}) \times Need_i 
\end{equation}

\section{Wealth Redistribution}
\begin{equation}
\textit{WelfareIndex}_i = 0.75\times (1 - \frac{max(0,L_i - H_i)}{L_i})+0.20\times (1 - \frac{H_i}{\textit{MaxH}})+0.05\times \frac{t_i}{100}
\end{equation}

\begin{equation}
\textit{GivePotential}_i = max(0,L_1 - h_i)
\end{equation}

\begin{equation}
\textit{NeedPotential}_i = 1 - \textit{WelfareIndex}_i
\end{equation}

\begin{equation}
\textit{TotalGivePotential} = \sum_{i=0}^{N}\textit{GivePotential}_i
\end{equation}

\begin{equation}
\textit{TotalNeedPotential} = \sum_{i=0}^{N}\textit{NeedPotential}_i
\end{equation}

\begin{equation}
\textit{Redistribute} = min(TotalGivePotential,\textit{TotalMachineMemory} \times \textit{gini}(\textit{WelfareIndex}))
\end{equation}
Where MaxH is the maximum observed H (footPrint) and 100 is the maximum throughput that the V8 will report.
\begin{equation}
\textit{Available} = max(0,\textit{TotalMachineMemory} - \sum_{i=0}^{N}L_i)
\end{equation}

\begin{equation}
\textit{Take} = max(0,\textit{Redistribute} - \textit{Available})
\end{equation}

\begin{equation}
L_i = L_i - \frac{\textit{GivePotential}_i}{\textit{TotalGivePotential}} \times Take + \frac{\textit{NeedPotential}_i}{\textit{TotalNeedPotential}}\times (Available + Take) 
\end{equation}

\section{Pascal}
\chapter{Conclusion}
\section{Future Work}
Attach the 
Add security
Control Semi Space?
State based policy

\begin{appendices}
\chapter{Benchmark Scripts}
The contents...
\chapter{Minimum Heap Size Measurements}
\label{minheapsize}
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpBinaryTree.png}
    \caption{Binary Tree Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpFasta.png}
    \caption{Fasta Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpKNucleotide.png}
    \caption{KNucleotide Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpRegexDNA.png}
    \caption{RegexDNA Benchmark.}
\end{figure}
\chapter{Policy Comparison}
Wealth Redistribution for 2 Binarytree benchmarks running in parallel limited at 400MB
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1\textwidth]{binarytree400MLeft.png}
    \caption{Binary Tree 1}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{binarytree400Mright.png}
    \caption{Binary Tree 2.}
\end{figure}
\chapter{Command Line}
\label{allcommands}
\begin{lstlisting}
Manager Commands 
________________________________________________________________________________
>> chhz [frequency in Hz(float)]
Change the machine polling frequency.
>> chv8 [V8Id(int)]
Change the V8 that the shell is set to.
>> dbg
>> echo [0/1 off/on(int)]
Toggle echo function on or off
>> help
   (? ) 
>> history
   (h ) Print command history
>> hz
Get the current polling frequency
>> listPolicies
   (lsp ) List available policies
>> listScenarios
   (listscen lscen ls ) Show a listiong of all scenarios
>> loadConfig [configuration(str)]
   (conf lc ) Load and apply configuration file
>> loadpolicy [policy name(str)]
   (ldp ) Load a difference memory management ploicy.
>> machines
   (m ) Status report of all machines, V8 and isolates.
>> policyname
   (p? ) Configure how the plotters behave, using a JSON string. This is applied to plotters created after this command is issued. options: makePNG(boolean) makeCSV(boolean)
>> policystats
   (ps ) Configure how the plotters behave, using a JSON string. This is applied to plotters created after this command is issued. options: makePNG(boolean) makeCSV(boolean)
>> registryIO
   (rio r? ) Get a summary of the network usage on the registry side
>> run [script(str)]
   (r ) Run a JS script on the V8 the shell is set to.
>> setMachineMemoryLimit [machine_id(str)] [memory_limit_in_MB(int)]
   (mlim ) Set the global memory limit for all JS instances per machine
>> setmax [isolateId(int)] [heap size in bytes(int)]
   (hard ) Set hard limit reccodendation to the isolate from the V8 the shell is set to.
>> setMaxPlotters [max(int)]
   (maxPlt mp ) Set maximum plotter windows allowed
>> setNewMachineMemoryLimit [memory_limit_in_MB(int)]
   (nmlim ) Set the global memory limit for all JS instances for new machines that connect
>> setPlotMode [mode(str)]
   (pmode pm ) Set the plot mode: NONE,MACHINE,ISOLATE,ALL
>> setPlotServerPort [port(int)]
   (plotport pp ) Restart the plotter server on a different port
>> setPlotterStartupConfig [JSON config(str)]
   (pltsconf ) Configure how the plotters behave, using a JSON string. This is applied to plotters created after this command is issued. options: makePNG(boolean) makeCSV(boolean)
>> snapshot [isolateId(int)]
Take a snapshot of an isolate form the V8 the shell is set to.
>> stats
Status report of all machines, V8 and isolates.
>> suggest [isolateId(int)] [heap size in bytes(int)]
   (s soft ) Send hard limmit reccomendation to the isolate from the V8 the shell is set to.
>> switch [machineId(str)] [V8Id(int)]
Change the machine and V8 that the shell is set to.
>> testScenario [path_to_scenario(str)] [path_to_collect_in(str)]
   (scenario rs t ) Run a testing scenario
>> togglePlotServiceLogging [ON/OFF(str)]
   (pslog tpsl ) Toggle PlotService logging
>> v8s
   (v ) Status report of all machines, V8 and isolates.
>> where
What V8 from what machine the shell is set to at the moment.
________________________________________________________________________________
\end{lstlisting}
Strings in () brackets are short forms for the command. 
\end{appendices}

%more accurate biblio
\begin{thebibliography}{9}
\bibitem{intro}
Gregor Richards, Andreas Gal, Brendan Eich, Jan Vitek,
\emph{Automated Construction of JavaScript Benchmarks},
\bibitem{v8gctour}
A tour of the V8 garbage collector,
\url{http://jayconrod.com/posts/55/a-tour-of-v8-garbage-collection},
\bibitem{nodejs}
NWJS Project
\url{http://nwjs.io/}
\bibitem{nwjs}
NodeJS Project
\url{https://nodejs.org/en/}
\bibitem{v8}
V8 Engine
\url{https://developers.google.com/v8/}
\bibitem{spidermk}
SpidermonkeyEngine
\url{https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey}
\bibitem{chakra}
Chackra Engine
\url{https://github.com/Microsoft/ChakraCore}
\bibitem{forseti}
Callum Cameron, Jeremy Singer, David Vengerov
\emph{The Judgment of Forseti: Economic Utility for Dynamic Heap Sizing of Multiple Runtimes},
\bibitem{powderplayer}
\url{https://github.com/jaruba/PowderPlayer}
\bibitem{whatsap}
\url{https://web.whatsapp.com/}
\bibitem{messenger}
\url{http://messengerfordesktop.com/}
\bibitem{devkit}
\url{https://github.com/printhom/devkit-core}
\bibitem{wunderlist}
\url{https://www.wunderlist.com/download/}
\bibitem{tycoongame}
\url{http://www.greenheartgames.com/app/game-dev-tycoon/}
\bibitem{welfareeconomics}
Deardorff, Alan V. (2014), "Welfare economics", Deardorffs' Glossary of International Economics \url{http://www-personal.umich.edu/~alandear/glossary/w.html#WelfareEconomics}
\bibitem{socialwelfarefunction}
Amartya K. Sen, 1970 [1984], Collective Choice and Social Welfare, ch. 3, "Collective Rationality." p. 33, and ch. 3*, "Social Welfare Functions." \url{http://www.citeulike.org/user/rlai/article/681900}
\bibitem{jsgrandpa}
Naomi Hamilton, “The A–Z of Programming Languages: JavaScript,” Computerworld, July 30, 2008, \url{http://bit.ly/1lKldIe}
\bibitem{jsdaddy}
 Paul Krill, “JavaScript Creator Ponders Past, Future,” InfoWorld, June 23, 2008, http://bit.ly/1lKlpXO; Brendan Eich, “A Brief History of JavaScript,” July 21, 2010, \url{http://bit.ly/1lKkI0M}
\bibitem{github}
GitHub, version control service based on git \hspace*{1em} \url{https://github.com/}
\bibitem{githut}
GitHut, Statistics for GitHub \hspace*{1em} \url{http://githut.info/}
\bibitem{gcpaper}
Paul R Wilson. Uniprocessor garbage collection techniques. In Memory Management, pages 1–42.
Springer, 1992.
\bibitem{v8sizebug}
V8 Maximum Memory Amount Per Isolate
\url{https://bugs.chromium.org/p/v8/issues/detail?id=847}
\end{thebibliography}
\end{document}
\pdfoutput=1

\documentclass{l4proj}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{url}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{lipsum}% http://ctan.org/pkg/lipsum
\usepackage{algorithm}% http://ctan.org/pkg/algorithm
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx

\usepackage{subcaption}% http://ctan.org/pkg/subcaption
\captionsetup{compatibility=false}
\DeclareCaptionSubType*{algorithm}
\renewcommand\thesubalgorithm{\thetable\alph{subalgorithm}}
\DeclareCaptionLabelFormat{alglabel}{Alg.~#2}
%TODO: relax introduction
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = black %Colour of citations
}

\colorlet{punct}{red!60!black}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\definecolor{darkgray}{rgb}{0.4, 0.4, 0.4}
%\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{editorGray}{rgb}{0.95, 0.95, 0.95}
\definecolor{editorOcher}{rgb}{1, 0.5, 0} % #FF7F00 -> rgb(239, 169, 0)
\definecolor{editorGreen}{rgb}{0, 0.5, 0} % #007C00 -> rgb(0, 124, 0)
\definecolor{orange}{rgb}{1,0.45,0.13}    
\definecolor{olive}{rgb}{0.17,0.59,0.20}
\definecolor{brown}{rgb}{0.69,0.31,0.31}
\definecolor{purple}{rgb}{0.38,0.18,0.81}
\definecolor{lightblue}{rgb}{0.1,0.57,0.7}
\definecolor{lightred}{rgb}{1,0.4,0.5}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
%V8 C++
\lstdefinelanguage{cpp}{
  morekeywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break,Isolate,CreateParams,New},
  morecomment=[s]{/*}{*/},
  morecomment=[l]//,
  morestring=[b]",
  morestring=[b]'
}
% CSS
\lstdefinelanguage{CSS}{
  keywords={color,background-image:,margin,padding,font,weight,display,position,top,left,right,bottom,list,style,border,size,white,space,min,width, transition:, transform:, transition-property, transition-duration, transition-timing-function}, 
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]',
  morestring=[b]",
  alsoletter={:},
  alsodigit={-}
}

% JavaScript
\lstdefinelanguage{JavaScript}{
  morekeywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  morecomment=[s]{/*}{*/},
  morecomment=[l]//,
  morestring=[b]",
  morestring=[b]'
}

\lstdefinelanguage{HTML5}{
  language=html,
  sensitive=true, 
  alsoletter={<>=-},  
  morecomment=[s]{<!-}{-->},
  tag=[s],
  otherkeywords={
  % General
  >,
  % Standard tags
  <!DOCTYPE,
  </html, <html, <head, <title, </title, <style, </style, <link, </head, <meta, />,
  % body
  </body, <body,
  % Divs
  </div, <div, </div>, 
  % Paragraphs
  </p, <p, </p>,
  % scripts
  </script, <script,
  % More tags...
  <canvas, /canvas>, <svg, <rect, <animateTransform, </rect>, </svg>, <video, <source, <iframe, </iframe>, </video>, <image, </image>, <header, </header, <article, </article
  },
  ndkeywords={
  % General
  =,
  % HTML attributes
  charset=, src=, id=, width=, height=, style=, type=, rel=, href=,
  % SVG attributes
  fill=, attributeName=, begin=, dur=, from=, to=, poster=, controls=, x=, y=, repeatCount=, xlink:href=,
  % properties
  margin:, padding:, background-image:, border:, top:, left:, position:, width:, height:, margin-top:, margin-bottom:, font-size:, line-height:,
  % CSS3 properties
  transform:, -moz-transform:, -webkit-transform:,
  animation:, -webkit-animation:,
  transition:,  transition-duration:, transition-property:, transition-timing-function:,
  }
}
\lstdefinestyle{htmlcssjs} {%
  % General design
%  backgroundcolor=\color{editorGray},
  basicstyle={\tiny},   
  frame=b,
  % line-numbers
  xleftmargin={0.75cm},
  numbers=left,
  stepnumber=1,
  firstnumber=1,
  numberfirstline=true, 
  % Code design
  identifierstyle=\color{black},
  keywordstyle=\color{blue}\bfseries,
  ndkeywordstyle=\color{editorGreen}\bfseries,
  stringstyle=\color{editorOcher}\ttfamily,
  commentstyle=\color{brown}\ttfamily,
  % Code
  language=HTML5,
  alsolanguage=JavaScript,
  alsodigit={.:;},  
  tabsize=2,
  showtabs=false,
  showspaces=false,
  showstringspaces=false,
  extendedchars=true,
  breaklines=true,
  % German umlauts
  literate=%
  {Ö}{{\"O}}1
  {Ä}{{\"A}}1
  {Ü}{{\"U}}1
  {ß}{{\ss}}1
  {ü}{{\"u}}1
  {ä}{{\"a}}1
  {ö}{{\"o}}1
}
%
\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                     % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\begin{document}
\title{Sociable Javascript}
\author{Milorad Liviu Felix}
\date{\today}
\maketitle
\educationalconsent
%
%NOTE: if you include the educationalconsent (above) and your project is graded an A then
%      it may be entered in the CS Hall of Fame
%
\newpage
\begin{abstract}
   As \textbf{JavaScript} has grown in popularity, it has also became more versatile. More applications running JavaScript on the same machine may result in greater memory contention among processes. To make the best use of system resources while maximising utilisation, the applications would need to be aware of each other's memory needs, and cooperate in order for them to continuously have access to the minimum running requirements. To achieve system-wide awareness at an individual application level, we propose a client-server model, where a manager process keeps track of all running client applications and controls how much memory they are allocated. We present a set of policies based on social welfare theory that model JavaScript execution environments as individuals and evaluate how they impact the execution speed and memory footprint of each application. An application with a low memory footprint, that has acceptable throughput, could make JavaScript a suitable choice for highly multiprocessing and elastic systems.
\end{abstract}
\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}
\chapter{Introduction}
%intro
\hspace*{3em} \textbf{JavaScript} is a highly dynamic language for web-based applications.\cite{intro}!!-!!-!!-!!%abstract. need to add anectode about how everything is modeled as an object and that is hard to interpret/exec 
 It began as a simple solution for animating web-page content, but has evolved into a \textbf{multipurpose scripting language} with growing support and popularity. A large part of the functionality of web products is now implemented in JavaScript and there are initiatives, such as NodeJS\cite{nodejs}, that aim to bring this language to the \textbf{server side}. Since the language is interpretive, browser vendors implement JavaScript \textbf{virtual machines} that perform \textbf{just-in-time} compilation to execute the code. Some of the most widely used examples are \textbf{V8} from Google Chrome\cite{v8}, Nitro from Apple Safari, Spidermonkey\cite{spidermk} from Mozilla Firefox and Chakra\cite{chakra} from Microsoft Edge.
\\\\%garbage collection
\hspace*{3em} One reason for the \textbf{considerable popularity} of the language is its \textbf{simplicity}. A key factor of this simplicity is that JavaScript programmers do not have to handle memory. This allows developers to focus on the high level functionality such as how an application responds to a certain request rather than on low level implementation details such as how much memory a new object needs and when that memory should be freed. The responsibility of memory management is passed onto the virtual machine that executes the program. While \textbf{memory allocation} may be straight forward (a new block of memory is requested from the host operating system when the application creates a new object), \textbf{freeing memory} cannot be done in the same manner, as an object that goes out of scope might still be referenced by a \textbf{live object}. The virtual machine needs to inspect the live objects and detect which ones have truly expired and free the memory they occupy. This process is called \textbf{garbage collection}.
\\\\%virtual machines optimisations
\section{Virtual Machine Optimisation}
\hspace*{3em} These \textbf{JavaScript virtual machines} are optimised to offer the best possible performance from a user perspective, this means that speed of execution and steady rendering are most important. In the case of V8, the engineers that designed it are using the term \textbf{``jank''} to refer to noticeable rendering pauses caused by JavaScript garbage collection and are currently striving to minimise it. One example of jank is when the user scrolls the page and the animation has noticeable pauses that make it look \textbf{discontinuous}. Jank occurs because in order to carry out garbage collection the execution of the JavaScript application needs to be paused. To reduce the impact observable by the user, garbage collection pauses are divided into small execution sequences and are interleaved with long execution sequences. This improves the user experience but increases the memory footprint of the application as unused memory is held for longer than necessary. Such a system is not concerned with conserving memory and cooperating with other processes in order to allow as many applications as possible to run on the system, but this behavior is justified as each tab in the browser needs to display as smoothly as possible.
\\\\%server side applications
%TODO: add some examples of nodejs services
\section{Multipurpose JavaScript}
\hspace*{3em} \textbf{JavaScript outgrew its original intended purpose} and has expanded to \textbf{server side applications} and native \textbf{client applications}. In the case of server side applications, the NodsJS framework is experiencing a growing adoption trend for services such as web-servers, push notification servers, server side voice recognition and other computation bound services. This is in part due to the fact that a large majority of the JavaScript library ecosystem is compatible with NodeJS leaving out only the libraries that utilise HTML document related methods and structures (which are not present in NodeJS). In this case, jank does not exist since no rendering is done, therefore garbage collection would only impact total execution time. Service providers would greatly benefit if these applications were to have a lower memory footprint (achieved by collecting garbage more intensely) as more processes can be run per single physical machine, thus increasing the service availability. Also being able limit memory expansion per process guarantees that system processes and other service specific administrative processes will always have enough memory to remain responsive, regardless of how loaded the client serving applications are. Elastic systems can benefit from a global service that controls memory usage of garbage collected systems as the limits can be tightened or relaxed depending on the load and total amount of memory made available at each point in time.\\%client side applications
\\\\
\hspace*{3em} JavaScript based \textbf{client side applications} are also beginning to emerge in the form of NWJS(Node Webkit JavaScript) applications. In essence this is a web browser rendering a local webpage which has access to JavaScript file system APIs and other native application functionality that is normally not included in regular web browsers for security reasons. This approach is gaining popularity especially among organisations that lack the human resources necessary to build different native applications for each platform they intend to support or want to deploy their existing web applications in the form of native applications. 
Examples of such native applications are: Powder Player - a video streaming application with torrent download and seeding integration\cite{powderplayer}, WhatsApp - a popular messenger application acquired by Facebook in 2014 \cite{whatsap}, Facebook’s messenger - Facebook's own messenger platform \cite{messenger}, DevKit - a modular integrated development environment \cite{devkit},
Wunderlist - a popular productivity application allowing users to create and share task lists\cite{wunderlist} and even a game named GameDev Tycoon\cite{tycoongame}. 
%kind of weak
Having a mechanism for controlling such an application's memory usage would allow the user to run many JavaScript applications concurrently while using an optimum amount of memory so that all the other processes can complete successfully. This way the user can play a game while listening to music and streaming files from the internet, all using JavaScript applications.
\\\\%purpose of the project
\section{Project Scope}
\hspace*{3em} The purpose of this project is to build a framework capable of \textbf{monitoring the memory usage} of every JavaScript running context and apply a memory management policy that will generate a limit for each one of them. Upon receiving its memory limit from the manager the JavaScript virtual machine will free more memory during garbage collection in order to comply.
\\\\ %motivation and social welfare
\hspace*{3em} The motivation for building such a system is improving the maximum possible \textbf{multi-programming degree}, availability and fault tolerance for services based on JavaScript applications, making this technology suitable for \textbf{multi-tasking and elastic systems}. The main benefit of enforcing a global memory utilisation policy over all of the JavaScript running contexts on a machine is reducing competition for resources and increasing cooperation. Garbage collection will be done more frequently, thus freeing up more memory and allowing more instances to run on the same machine. The end goal would be to increase the multi-programming level without hindering performance.\\
\hspace*{3em} Through the coordinated management of memory based on global information, applications achieve a form of cooperation much like individuals cooperate and responsibly share resources with each other, in order to maintain a necessary level of comfort. The key factor to the success of this framework would be to maintain acceptable throughput levels for each JavaScript appliaction. This translates directly to how long each program takes to complete. If execution time increases considerably, the applications become unfeasible. In order to find a balance between throughput and memory size, the framework models execution contexts as individuals and applies a social welfare function in order to determine how much memory each individual is allowed to use. We will attempt to build such a cooperative memory manager using concepts from \textbf{social welfare theory}.
\\\\
There are two main components to this project:
\begin{itemize}
\item The \textbf{manager} - receives memory usage information, applies the management policy and then issues limits to each execution environment.
\item a modified \textbf{JavaScript virtual machine} executes JavaScript, reports runtime context characteristics (heap size, throughput, etc) and enforces memory limits received from the manager.
\end{itemize}
The manager is a Python application and the virtual machine selected for this project is Google's V8 engine. The manager will be central to evaluating the performance of each script in relation to the applied policy using the characteristics received from the V8.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.75\textwidth]{SimplifiedOverall.png}
    \caption{Overall project diagram.}
\end{figure}

The approach adopted was similar to the Java Forseti system developed at the University of Glasgow\cite{forseti}. To implement this system, changes need to be done to the V8 engine and a manager process that would implement the policy would need to be built. The V8 engine would need modifications that allow dynamic expanding and shrinking of a running context's (isolate) heap size and a network client that receives and executes commands issued by the manager. This can be a challenging task since the V8 project consists of \textbf{800,000+ lines of code}. %diagram

%The system would work as follows: the manager process starts a registry server that listens for connections from V8 instances. A new V8 instance would run either by itself or inside the Chrome browser and would connect to the manager process. As soon as the manager detects a new V8 instance, it starts polling it for status information (heap memory used, throughput, etc). The manager will use this information to calculate how large the heap of each isolate should be and will send the calculated value back to the V8. The engine will then try to adapt each isolate's memory consumption to match the recommended value by increasing the number of garbage collection operations.
%expand
\section{Outline}

Below is the structure of this report:

\textbf{Chapter 2 - Background:}
Background information

\textbf{Chapter 3 - Requirements:}
Functional and non-functional requirements of the management framework.

\textbf{Chapter 4 - Design:}
Design of the management framework as well as of the required changes to the V8 engine.

\textbf{Chapter 5 - Implementation}
Implementation of the management framework and of the changes to V8.

\textbf{Chapter 6 - Evaluation:}
Empirical evaluation of the effectiveness of the framework when using various memory management policies.

\textbf{Chapter 7 - Conclusions}
Conclusions and future advances.


\chapter{Background}
%java script
%garbage collection
%v8
\section{Welfare Economics}
\hspace*{3em} \textbf{Welfare economics} is a branch of economics that uses microeconomic techniques to evaluate well-being (welfare) at the aggregate (economy-wide) level.\cite{welfareeconomics} The typical evaluation begins with the derivation of a \textbf{social welfare function}. In welfare economics, a social welfare function is a function that ranks social states (alternative complete descriptions of the society) as less desirable, more desirable, or indifferent for every possible pair of social states. Inputs of the function include any variables considered to affect the economic welfare of a society.\cite{socialwelfarefunction} This is then used to rank economically feasible allocations of resources. JavaScript applications can be modeled as individuals using a a combination of the characteristics of running contexts as input values for the social welfare function. Such characteristics are heap size, available memory, throughput, etc. The exact choice of the social welfare function, selected set of runtime context characteristics and the way these characteristics are mapped to the input values of the function are what we call a \textbf{policy}. This project aims to evaluate the effectiveness of various policies in relation to different types of JavaScript applications: web pages scripts, IO bound standalone applications, computation bound standalone applications. Some policies may be better suited for standalone applications while others may work work well with web-page scripts, some might perform well overall. 
\section{JavaScript}
\hspace*{3em} In 1994, \textbf{Netscape} developed a web browser that was meant to exploit the potential of the emerging \textbf{World Wide Web}, its name was Netscape Navigator. The engineers behind the browser quickly realized that the Web needed to be more dynamic as even basic input validation had to be done by the server (requiring the browser to send the data over the network to the server and receive feedback). Later in 1995, a debate began among the engineers at Netscape about whether to add a static or scripting language to their browser. The proponents of a scripting language offered the following explanation:\cite{jsgrandpa} 
\textit{``We aimed to provide a “glue language” for the Web designers and part time programmers who were building Web content from components such as images, plugins, and Java applets. We saw Java as the “component language” used by higher-priced programmers, where the glue programmers—the Web page designers—would assemble components and automate their interactions using [a scripting language].''}
Netscape management had decided that a scripting language had to have a syntax similar to Java’s largely because of their collaboration with \textbf{Sun}, the company that created the \textbf{Java programming language}. In late November 1995, Navigator 2.0B3 came out and included the prototype, which continued its early existence without major changes. In early December 1995, Java’s momentum had grown and the language was renamed, to its final name, \textbf{JavaScript}.\cite{jsdaddy}
\\\\
\hspace*{3em} JavaScript has since grown to be one of the most popular programming languages. If popularity were to be judged by the number of projects built with JavaScript, then it has become the most popular language on GitHub\cite{github} (which in turn is one of the most popular version control services):

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{JsPop.png}
    \caption{JavaScript 1st popular language on GitHub.\cite{githut}}
\end{figure}
The popularity of a programming language comes from the size and activity of its community (the developers that build projects with the said language) and this means that JavaScript has a vast and active one. !!-!!-!!-!!
%add some sort of conclusion = JS could be good to use in backend / native side
\section{Garbage Collection}
%This chapter provides a high level overview of numerous garbage collection techniques including key defini-
%tions which shall be used throughout this report. For a fuller introduction to garbage collection techniques see
%Wilson[18] who presents a comprehensive survey paper of the basic techniques. Many of the basic memory sys-
%tem elements are shown graphically in Figure 2.1. This figure is intended to be used as a reference when reading
%this section.
\begin{figure}[!ht]
  \centering
    \includegraphics[height=15em]{Heap.png}
    \caption{Basic Memory System Diagram}
\end{figure}
\section{Why control resource allocation}
\hspace*{3em} To better portray the benefit of controlling resource allocation, consider an elastic data centre running JavaScript application to service various client requests as well as administrative tasks. The elastic nature of the environment would require increasing or decreasing the number of active host machines as well as the number of active servicing application depending on the load. 
\\\\
\hspace*{3em} Without any supervision, JavaScript application would simply use as much memory as necessary to maximise performance. This would be done without any knowledge or consideration for the other processes running on the host machine. Performance is maximised by keeping garbage collection pauses as short and far apart as possible, causing the program to retain more memory than it actually needs. This would not pose any problems in situations where there is plenty of memory, but as the number of processes running in parallel increases so does the memory contention.
\\\\
\hspace*{3em} In the situation where the available memory was nearly depleted, newly started application would suffer from memory starvation causing them to run with very low throughput or even fail. Existing applications could also suffer as their needs could change over time (a section of code that is more memory intensive executes), as there is no way to coordinate the JavaScript run-time environments in order to maximise the throughput of every application by forcing some to relinquish more memory and giving it to the ones in need. In a situation with no available memory, applications would start trashing which would gravely impact the overall performance of the system. In this scenario, if the system administrator did not reserve an amount of memory for system processes, the operation of the system would slow down considerably or even halt. 
\\\\
\hspace*{3em} With no supervision framework, the system administrator would have to estimate how many applications can run on a machine, depending on the amount of memory each machine has, and enforce such a limit on every machine in the environment. This solution is not viable for a modern elastic environment where the machine count is the thousands and new machines are added or removed depending on system load. 
\\\\
\hspace*{3em} A supervising framework would calculate and enforce a memory limit for every JavaScript application it manages in an effort to maximise their throughput. Managed applications would not be allowed to retain unused memory if there are other applications that need more memory. In contrast with the situation presented above, where no supervisor was present, portions of memory are taken from carefully selected applications and given to the newly started or low throughput programs. The framework can also be configured to assign limits within a certain threshold in order for the total memory consumption of JavaScript programs to be lower than the total available memory. This would offer the guarantee that system processes have a dedicated portion of memory at all times.
\\\\
\hspace*{3em} A JavaScript program would fail only if its assigned memory limit becomes lower than its minimum heap size. Since this size is considerably smaller than the actual unrestricted memory usage (see appendix \cref{minheapsize}), more applications could safely run on the same machine than in the scenario where no supervisor is present. This would increase the productivity and responsiveness potential of a host machine. Knowing the minimum heap size of a program could also enable the framework to perform an acceptance check for new applications starting on host machine:
\begin{equation} 
\textit{AllocatableMemory} = \textit{TotalAllocatableMemory} - \sum_{i=0}^{N}\textit{MinimumHeapSize}_i
\end{equation}
If the value of the expression above is lower than the minimum heap size, the new application can not be allowed to start as it is highly likely to fail. Using this check a machine capable of hosting the new application could be found.
\\\\
\hspace*{3em} A supervisor framework uses insight provided by the running applications to make resource allocation decisions. In a normal setup, this insight is not needed since applications are entitled to an equal share of the system resources by default. This allows any individual application to make demands best suited for its well being without being concerned with the status of the others. Having insight provided by every running applications has the main advantage of allowing a supervisor to work towards the well being of the group rather than of an individual. This way, memory is used more efficiently, more applications can run at the same time and newly started applications are less likely to suffer from memory starvation if the other running applications utilise most of the available memory.
\section{Related Work}
\subsection{Virtual Machine Inspectors}
\hspace*{3em} - already used by industry, too heavy in their analysis - goes too deep - performance cost (proof) or if no performance cost, too much data to analyse.
\subsection{Directly Related Work}
FORSETTI\\
Throughput, Heap curve\\
Control theory?
\chapter{Requirements}
%\hspace*{3em} (Does not really make sense, need to rephrase ->)Due to the exploratory nature of the project at hand, some of the functional and non functional requirements of the system have been drawn based on the features offered either by the V8 engine or by the limitations of the technologies used to build the framework. 
\section{Non-Functional Requirements}
\begin{itemize}
\item Detect V8 instances within the managed environment and apply a selected memory management policy.
\item Control the memory limits for all the Isolates within the managed environment without causing any of them to terminate execution abnormally.
\item Automatically detect new V8 processes and add them to a pool of managed processes.
\item Automatically detect when new Isolates are created by their host V8 processes and add them to a pool of active isolates.
\item Automatically detect when Isolates finish execution and remove them from the pool of active isolates.
\item Automatically detect when V8 processes finish execution, remove all isolates they host from the pool of active isolates and remove the process form the pool of managed processes.
\item Calculate limits at a set frequency for all active isolates.
\item Service a large number of V8 processes without unpredictable delays.
\item Capture every parameter of the isolate updates.
\item Plot selected status features of every isolate in the system on screen for the user to analyse as the framework is running.
\item Save the selected status features of an isolate's entire execution in a file for post-execution analysis.
\item Disable the feedback module so that the application works solely on enforcing memory limits.
\item Give access to features of the entire framework to the user.
\end{itemize}
\section{Functional Requirements}
\begin{itemize}
\item Given a new V8 process connection, update the pools of managed machines, V8s and isolates.
\item Given a new V8 process connection, use the remote IP address as a unique identifier for the host machine, assign a new numeric ID value, unique within the context of the host machine, to represent the V8. Also store the communications channel (socket) used to contact this V8.
\item Given a new Isolate, assign it the same ID used by its host V8 process and store it in the managed isolates pool.
\item Given a Machine Id, V8 Id and an Isolate Id correctly retrieve the status information of the Isolate and the communications channel needed to communicate with its host V8 process.
\item Given a pool of active isolates send a status update request to the correct host V8 processes. 
\item Given a list of isolates and a maximum available memory value and output a list of memory limits for each isolate
\item Given a collection of status values for an isolate, plot the selected (relevant) ones on screen in the window corresponding to the isolate.
\item Given a collection of status values for an isolate, append them to a file containing the full history for that isolate.
%are these non-functional?
\item Allow the user to set the polling frequency of the manager
\item Allow the user to select the memory management policy used to calculate the memory limits.
\item Allow the user to get status information about the managed isolates and other framework facilities.
\item Allow the user to configure the plotting facility behaviour: such as whether a full history file should be created, PNG files should be created or live plotting should be done
\item Allow the user to set memory limits on active isolates
\item Allow the user to set maximum available memory for managed machines
\item Allow the user to run automated testing scenarios to evaluate the existing policies.
\end{itemize}
\newpage
\chapter{Design}
CHAPTER DESCRIPTION
\section{Overview}

The overall framework has two main components:
\begin{itemize}
\item A \textbf{manager} - keeps track of active V8 instances, polls V8 instances for status information periodically, groups and plots the status information, calculates the memory allowance for each V8 Isolate, sends the appropriate commands containing the memory limits.
\item A \textbf{modified V8 engine} - connects to manager, retrieves status information and responds to poll requests and commands, depending on current memory limit: intensifies or relaxes garbage collection process.
\end{itemize}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{OverallFramework.png}
  \caption{Overall project diagram detailed.}
\end{figure}
\hspace*{3em} In distributed systems a high per node multi-programming degree translates to high availability. This kind of environment also has potential to behave in an elastic way, making more resources available when the load increases and reducing the utilised resources when it diminishes. This means that our framework would have a greater impact when applied to a cluster of computers running JavaScript applications rather than a single computer.\\
\hspace*{3em} In order to adapt to this scenario the interaction between the V8 instances and the manager is done through the network, using TCP/IP. This allows the manager process to reside on any machine in a network and coordinate the memory usage of all the V8 instances running within the cluster. This makes the framework very adaptable to various use scenarios. For example: if the frameworks is to be used on a single computer it becomes a special case of the general model, a cluster with one node.
\\\\
\hspace*{3em} A \textbf{JSON} protocol is used to represent the commands and updates that are exchanged by the V8 instances and manager process. JSON is a good format option as it allows easy extension of the protocol schema, by simply adding additional keys the the concerned entities.
\begin{lstlisting}[language=json,firstnumber=1]
{
  "global":{"action":"","error":"", ... },
  "TotalIsolates":Integer,
  "isolates":{
    "1":{ "action":"","error":"", "heap":Integer,"throughput":Float,... },
    "2":{...}
    ...
  }
}
\end{lstlisting}
Here are the possible values that the \textbf{action} fields can have:\\\\
\begin{tabular}{  l  l  l  l  }
  Action & Global & Per Isolate & Description \\
\hline
  status & Yes & Yes & Isolate status request packet\\
  update & Yes & Yes & Isolate update response packet\\
  set\_heap\_size & No & Yes & Sets the heap size threshold over which the GC should intensify\\
  set\_max\_heap\_size & No & Yes & Sets the absolute maximum size the isolate can have\\
  terminated & Yes & Yes & V8 notifies the manager that one of its isolates has finished execution\\
\hline
\end{tabular}
\section{V8}
\hspace*{3em} The V8 virtual machine is based on isolated execution environments, each application runs in an isolated environment without the possibility of accessing resources owned by other applications running within the same V8 process. These isolation environments are called \textbf{isolates}. In essence, each isolate is an instance of the V8 virtual machine, having its own \textbf{heap space}, \textbf{garbage collector} and \textbf{compiler}. Only one thread can access an isolate at a time in order for the isolation to be maintained. 

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{V8Internals.png}
  \caption{V8 Internal Architecture.}
\end{figure}

A \textbf{context} defines a script execution environment by defining an object in an isolate's heap as a global object. Therefore, many contexts can exist in a given isolate and can also share any of their objects easily.
\begin{lstlisting}[style=htmlcssjs]
 <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/libs/jquery/jquery-1.7.2.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/libs/jquery/jquery-ui.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/video/new/jwplayer/jwplayer.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/scripts/bbq/jquery.ba-bbq.min.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/0t4/generic/scripts/raccoon.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/jquery.flexslider.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/main.js"></script>
        <script type="text/javascript" src="http://www.gla.ac.uk/1t4/generic/scripts/video.js"></script>
\end{lstlisting}
In the above extract from the HTML source of Glasgow University's website, each HTML script tag will cause the V8 to create a new context. Every script will be loaded in a different context but will share global variables.\\\\
The \textbf{heap} is divided into a set of spaces:
\begin{itemize}
\item \textbf{New Space} - Most objects are allocated here. This space is small and is designed to be garbage collected very quickly, independent of other spaces. 
\item \textbf{Old Space} - holds most objects that have pointers to other objects or contain raw data. Objects that survive the new space for a certain amount of time are moved here.  
\item \textbf{Code Space} - contains the instructions that comprise the compiled scripts
\item \textbf{Map Space} - Cells, Cell Properties and Maps !!-!!-!!-!!
\item \textbf{Large Object Space} - contains objects that are larger than the size limits of the other spaces. These objects are never moved by the garbage collector.
\end{itemize}
Each space is divided into a set of pages. A Page is a contiguous chunk of memory, allocated using operating system calls. Pages are always 1 MB in size and 1 MB aligned, except in large-object-space, where they may be larger. In addition to storing objects, pages also contain a header (with various flags and meta-data) and a marking bitmap (used to indicate which objects are live). Each page also has a slots buffer, allocated in separate memory, which forms a list of objects which may point to objects stored on the page.\cite{v8gctour}
\\\\
\textbf{Garbage collection} is comprised of two algorithms:
\begin{itemize}
\item \textbf{Scavenger} - is a copying garbage collection based on Cheney's algorithm. It only operates on the new space and occurs frequently.
\item \textbf{Mark Compact} - operates on the every other space except new space. It does not perform compaction on the large object space.
\end{itemize}

New-space is divided into two equal sized semi-spaces: to-space and from-space. Most allocations are made in to-space (with the exception of certain kinds of objects, such as executable Codes which are always allocated in old-space). When to-space becomes full, to-space and from-space are swapped. Then the live objects are copied out of the from-space either back into to-space or to old-space. Copying the objects into to-space also has the effect of compacting the space which improves locality of reference which, in turn, improves performance.%!
\\\\
Mark-Sweep \& Compact !!-!!-!!-!!
\\\\
\hspace*{3em} The garbage collection process incurs a certain performance cost. While actual memory \textbf{deallocation} can be done in \textbf{parallel} with the execution of JavaScript, the marking, moving and copying of live objects is much harder to parallelise. This is why garbage collection suspends the execution of hosted application. Since the new space is small, the frequent invocation of the Scavenger does greatly impact performance. The Mark-Compact on the other hand requires considerable pauses. To mitigate this, incremental marking has been implemented as well as a form of a deadline for each garbage collection pause. This way, the large pauses are divided into smaller ones causing unused memory to remain allocated for a longer period but improving the user perceived execution delay.

\subsection{Modifications}
\hspace*{3em} For the purpose of this project, the V8 engine had to be modified in order to communicate and comply with the manager process. This required both changes to existing code and additions of new code. Below is an overall diagram of the changes and additions:\\
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.85\textwidth]{V8Modifications.png}
  \caption{V8 modifications.}
\end{figure}\\
\begin{itemize}
\item \textbf{Heap} modifications allow setting a heap size limit and retrieving information about the memory usage (used memory, available memory and old space size). If the total heap size is larger than the set limit, the garbage collector will try to free as much memory needed to comply with it. Otherwise, when the heap size nears the set limit, garbage collection work intensifies to make sure it stays below the limit.
\item \textbf{Isolate} modification keep track of all the active isolates within the V8 process, measure execution and garbage collection times and calculate per isolate \textbf{throughput}. When a new isolate is crated, the tracker assigns it an numeric ID and adds it to a list of active isolates. When it finishes execution, its assigned ID is marked as free and the isolate is removed from the list.
\item A \textbf{Networking} client execution thread has been added to the V8 process for it to communicate with the manager. It is responsible with connecting to the manager, dividing the network data stream received from the manager into request packets, decoding them and performing the required actions and sending a response to the manager.
\item \textbf{Encoding} is nested, the first form is JSON which gets encoded to Base64. The latter uses a restricted set of characters to represent the payload which allows separating packets using ASCII characters that are not part of Base64. This allows the JSON payload to contain any symbols in its fields (even the packet separator character) without altering packet boundaries which simplifies the decoding process.
\item \textbf{Configuration} is done through a text file placed in the same folder as the V8 binary. This is meant to make the modified V8 more adaptable to other projects such as NodeJS and Chrome. If command line arguments were used in stead, they would have to be mirrored in both NodeJS and Chrome. The configuration file contains the IP address and port of the manager machine.
\end{itemize}
\section{Manager}
% High level description of the manager
\hspace*{3em} The main function of the \textbf{manager process} is to control the \textbf{memory limits} of each isolate. To do this, it needs to keep \textbf{track} of \textbf{active isolates}, \textbf{poll for status updates}, calculate new memory limits for every isolate and \textbf{give feedback} to the user on the status of the system. These functions have been divided into three main components: \textbf{Tracking}, \textbf{Management} and \textbf{Plotting}. The figure below is intended to be used as a reference when reading the remainder of this chapter.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1.0\textwidth]{PythonManager.png}
  \caption{Manager architecture.}
\end{figure}
\subsection{Tracking}
\hspace*{3em} This module is responsible with interacting and keeping track of the active isolates through the coordinated use of its components: \textbf{Registry Server}, \textbf{Communicator} and \textbf{Registry}. From the point of view of the framework, this module offers a means of communication with active isolates.
\\\\ %DESIGN_DECISION
\hspace*{3em} The registry maintains a \textbf{representation of the environment} managed by the application. Isolates are grouped together based on the V8 process they belong to and the machine they run on. The listing below shows the structure of the registry:
\begin{lstlisting}[language=json,firstnumber=1]
[{
  "id":"127.0.0.1",
  "v8s":[
    {"id":1,"isolates":[
      {"id":1,"heap":40542,"throughput":1.5},
      {"id":2,"heap":150241,"throughput":15.5},
    ...]
  },
    {"id":2,"isolates":[
    {"id":1,"heap":20541,"throughput":0.56},
        {"id":1,"heap":120443,"throughput":5.21},
    ...]
  },
  ...]
}, ... ]
\end{lstlisting}
In the case portrayed above, there are two V8 processes running on a the same machine as the manager process, each having two isolates. Using a hierarchical storage structure has the advantages of \textbf{minimal data redundancy}, ease of \textbf{extensibility} and \textbf{high topology fidelity}. The memory limits produced by the manager must not exceed the available memory of each machine, this requires knowing the provenience of each isolate. Each isolate is associated a local ID by its host V8, this is used to send memory limitations and other commands to the correct isolates. In order to send the commands to the right receiver, the active communications channel for each V8 process needs to be stored as well. If a non hierarchical structure such as a list were to be used, the aforementioned aspects would be more difficult to manage: the communication channel would be stored inside each isolate record adding one redundant field (many isolates can have the same host V8 process), mapping isolates to their host V8 processes and to their host machines would add even more redundant fields, determining which isolates belong to the same machine would become less efficient as it would require iterating through the entire list and mapping isolate updates coming from the network to their respective list records would require using a composite key in order to avoid iterating through the list. !!-!
\\\\
\hspace*{3em} The communicator represents an open channel to one V8 process. It handles encoding, decoding, sending and receiving messages to/from the V8. A communicator can represent at most one V8 instance at any given time.\\
\hspace*{3em} The Registry Server is responsible for servicing new connections from V8 instances to the manager. Once a new V8 engine connects to the manager, a record is added to the registry. A new communicator is created for the V8 and is added to its registry record. When a V8 finishes execution (or terminates abnormally), its communicator detects the closing of the channel and removes the corresponding V8 record from the registry. Since the communicator is stored in the V8 registry record, this will cause the communicator to cease to exist. 
\subsection{Management}
\hspace*{3em} The management module is responsible for \textbf{controlling the active isolates} by polling for updates, running a policy program that calculates memory limits, sending the calculated limits to the corresponding V8 processes and providing control over the framework to the user. The constituent components of this module are: the \textbf{Policy Executor}, \textbf{Policy Scripts} and a \textbf{Command Line Interface}.
\\\\
\hspace*{3em} The \textbf{Policy Scripts} are a collection of scripts that can be \textbf{loaded} into the manager framework \textbf{at run-time}. Only one such script can be running at any give time. A policy script receives a list of isolates and a maximum memory amount as input and \textbf{outputs the memory limits} for each of the provided isolates. All of the isolates in the input list run on the same machine, the maximum memory amount represents the maximum quantity of memory that JavaScript applications can use on the machine in question. This limitation reflects the fact that isolates running on one machine can not be allocated memory from multiple machines, therefore the total memory granted to the isolates can not be larger than the amount of physical memory available to the host machine !!-??-!!. It follows from this that the policy script needs to be run once for each machine managed by the framework. 
\\\\
\hspace*{3em} The \textbf{Policy Executor} regularly \textbf{polls} every V8 process present in the registry for status updates. These updates contain information such as: \textbf{in use heap size}, \textbf{total heap size}, available memory and \textbf{throughput}, which gets \textbf{copied into} the corresponding isolate record from  \textbf{the registry}. This information is used by the policy script to decide how much memory an isolate should have. The executor then groups all of the isolates based on their host machine and runs the current policy script for each machine.
\\\\
\hspace*{3em} The \textbf{command line interface} provides user access to the manager's functionality. Supported operations include changing the used policy script, changing the frequency of the status update polls, getting the latest status information of managed isolates, setting an isolate's memory limit, etc. This component is central to the evaluation as it allows the framework to test multiple policies without the overhead of restarting the whole infrastructure for every test, faulty policies can be detected during execution and swapped with correct ones, the full history of the status updates can be stored in files and examined post-execution or it can be plotted in real time on screen.
\\\\
\hspace*{3em} These three components come together to form the core of the framework by generating the memory limits for each manged isolate and allowing the user, the ultimate judge of the framework's effectiveness, to be part for the process and to observe its results in real-time. 
\subsection{Plotting}
\hspace*{3em} \textbf{Feedback} is crucial to evaluating the effectiveness of the policy used and, in turn, of the whole framework. This is why the manager application has a component dedicated to \textbf{gathering every status update} received by the registry and plotting a selected set of values on screen. Each full screen of plot history is saved in a PNG file, while the full history of the isolate's selected status values is saved to a CSV file for post-execution analysis. This module is comprised of three components: \textbf{Plotter}, \textbf{Plot Server}, \textbf{Plotting Service}.
\\\\
\hspace*{3em}  The \textbf{plotter} has the sole responsibility of receiving plot data, drawing it on screen and saving it to a file. It is modeled as a separate process from the manager framework. Plotters are started on demand, depending on how many isolates are being managed, each one represents a single isolate. 
\\\\
\hspace*{3em}  The \textbf{plotting service} is responsible with mapping a plot stream to one plotter process. A plot stream is comprised of the stream of status updates concerning one particular isolate. This service is responsible with detecting new streams, starting plotter processes for them and sending the plot data to the correct plotter processes. When a stream ends, because there is considerable overhead for creating a new process (and a new graphical window for drawing the plot), the plotting service keeps its corresponding plotter process in an idle state until a new stream is detected.
\\\\
\hspace*{3em} The \textbf{plotting server} has a function very similar to the registry server discussed in section 4.3.1. It starts plotter processes, when requested by the plotting service, and waits for them to connect in order to mark them as idle(ready to plot). The plotter processes are kept in a stack until they are needed by the plotting service. When a stream ends, the plotting service returns the plotter process to the server's stack in order to wait for a new stream to start.
\\\\
\hspace*{3em} The approach of having multiple separate processes handling plotting was chosen over having one process updating multiple windows (or multiple subplots) mainly because the library used is not designed to manage multiple independent plot windows but also to increase flexibility. With this model some plots (or all of them) could be offloaded to a different machine. !!-??  
\section{Software Engineering}
Separation of concerns\\
Extensibility - properties can be added and removed\\
Modularisation in Folders with closely related code\\
Pluggability of policy - loose coupling\\
!!-!!-!!-!!
\newpage
\chapter{Implementation}
CHAPTER DESCRIPTION
\section{Overview}
\hspace*{3em} There are three may areas of the implementation
\begin{itemize}
\item Building the manager framework
\item Changing the V8 engine to allow it to be controlled by the framework
\item Building a V8 wrapper responsible with running JavaScript applications specified through command line arguments.
\end{itemize}
\hspace*{3em} A V8 isolate, by itself, is simply an execution environment, the specific script that needs to run has to be \textbf{compiled} and \textbf{loaded} into the isolate. This is done using the functions provided by said isolate. The \textbf{V8 wrapper} is a C++ application that creates one isolate, takes in a list of scripts, compiles them and runs them inside the isolate. It also takes a size expressed in megabytes and sets it as the maximum heap size of the isolate.
\\\\
\hspace*{3em} The \textbf{Google V8} engine is implemented in \textbf{C++}, amounting to 800,000+ lines of code. Changing it requires using the same language which does not allow much freedom of choice. However, the management framework is an independent process and can be implemented in any language. \textbf{Python} was chosen for this task for the following reasons:
\begin{itemize}
\item It is a high level language with a small code footprint
\item It is interpreted, which allows loading and executing code at run-time and also eliminates compilation waiting time. (The V8 wrapper, despite its small size, has a compilation delay of around 30 seconds)
\item It has extended support from its community with plenty of useful libraries available
\item Has built in support for most of the required constructs to build the management framework including popular data representation protocols such as Base64 and JSON.
\end{itemize}
\hspace*{3em} The changes carried out on the V8 engine involve allowing the heap size limit to be set at run-time as well as adding a network client responsible with connecting to the manager framework, applying the limits (or other commands) received from the manager and replying with status updates.
\\\\
\hspace*{3em} JSON was used for the communication protocol employed by the V8 instances and the management framework because it is human readable and supports nesting well. This is appropriate as the project aims for correctness rather than performance at this stage. Human readability allows for easy debugging while nesting support contributes to a clear representation of the environment topology.
\\\\
\hspace*{3em} The manager framework implementation uses built in python functions for JSON and Base64 encoding and decoding while the V8 changes use custom built Base64 functions and a third party JSON C++ library.
\section{V8 Client}
\hspace*{3em} The main responsibility of V8 is to run scripts as efficiently as possible. Any form of \textbf{computation} not related to executing the scripts would be perceived as \textbf{overhead} by the user. Garbage collection is one example of such additional computation as it is responsible with freeing memory rather than advancing the execution of the hosted scripts. For this reason, collection pauses are kept as short and far apart as possible. The \textbf{changes} added to V8 for the purpose of this project are not related to script execution which would classify them as computational overhead. For this reason, the changes were designed to have a \textbf{minimal performance impact}. This was achieved through a set of implementation decisions detailed below.

\subsection{Enforcing Limits}
\hspace*{3em} By design, each V8 isolate is configured with memory limits for its old space and new space when the isolate is created.
\begin{lstlisting}[language=cpp]
Isolate::CreateParams create_params;
create_params.constraints.set_max_old_space_size(max_heap);
create_params.constraints.set_max_semi_space_size(16);

Isolate* isolate = Isolate::New(create_params);
\end{lstlisting}
\hspace*{3em} The memory spaces constituting the heap are divided into \textbf{1 megabyte pages}. The two functions from the listing above take in values representing a number of megabytes. Since this is an extract from the V8 wrapper, the new space size is set to 16 megabytes, while the old space is set to the value of the first command line argument. This also determines the level of \textbf{granularity} that the manager framework can use to determine memory limits. According to the creators of V8, the maximum amount of memory an isolate can use is \textbf{1 gigabyte}. Any value above that would cause the garbage collector to behave erratically.\cite{v8sizebug} This gives the manager a \textbf{range of 1000} possible memory limit values enforceable by V8.
\\\\
\hspace*{3em} When a new isolate is created, the value of the argument passed to set\_max\_old\_space\_size() method is copied into the \textit{max\_old\_generation\_size\_} member variable of the heap class. This class models the heap of a single isolate, it holds pointers to all of the spaces comprising the heap and contains member methods that control garbage collection. The heap is allowed to expand up to the limit set at isolate creation. Normally this limit is larger than the initial heap size. However, if the limit is smaller than the current heap size, the garbage collector will strive to free as much memory as possible in order to comply with it. This enables enforcing heap memory limits at run-time by simply updating the  \textit{max\_old\_generation\_size\_} variable. To do so, a setter method called \textit{setMaxOldGenerationSize(int)} has been added to the heap class.  %CONCURRENCY?
\\\\
\hspace*{3em} Another way of enforcing memory limits at run-time would be to modify the garbage collector so that it runs until the size of the heap becomes smaller than the limit or until no more memory can be freed. This is not a preferable solution because it would override the optimisations employed by the designers of V8 by performing long garbage collection runs whenever the limit becomes lower than the current heap size, making them much more obvious to the user. This approach also adds additional computation to the garbage collection process when compared to a simple copy operation employed by the setter function mentioned above.
\subsection{Measuring Throughput}
\hspace*{3em} An \textbf{important metric} that needs to be calculated and reported back to the manager is the application \textbf{throughput}:
\begin{equation}
throughput = \frac{\textit{Execution interval}}{\textit{Garbage Collection interval}}
\end{equation}
\hspace*{3em} This reflects how much time is spent executing JavaScript code versus the time spent performing garbage collection. Therefore, a throughput of 1 means that V8 spends an equal amount of time executing the application and collecting garbage. A value greater than one means more time is spent executing the application while a value lower than 1 means that more time is spent performing garbage collection. The latter implies that the application is somewhat "struggling" to execute, as more work is put into freeing memory rather than execution.
Ideally, more time should be put into executing the application than garbage collection. This is what V8 normally optimizes for by keeping garbage collection pauses small and far apart. A high throughput implies reduced jank in observed by the user in the browser.
%Ideally, an application would experience an execution pause only when the operating system performs a context switch in order for other processes to get a chance to run. Garbage collected applications add the overhead of pausing the application in order to collect unreachable memory and make it available to the application or return it to the operating system.
\subsection{Compiling Status Information}
text
\subsection{Server}
text
\subsection{Communication Protocol}
text
\section{Manager}
Plotting configuration - makes pictures of the whole graph history and CSV file with entire history
\\Locks and queues
\\Data Flow through framework
\\Frequency of polling - net load estiamte, policy execution, configurability
\\Logging + configurability
info
\begin{table}[H]%
\begin{subalgorithm}{.5\textwidth}
\begin{algorithmic}[1]
  \Procedure{GarbageCollection}{}
    \State $r\gets a\bmod b$
    \While{$r\not=0$}
      \State $a\gets b$
      \State $b\gets r$
      \State $r\gets a\bmod b$
    \EndWhile
    \State \textbf{return} $b$\Comment{The gcd is b}
  \EndProcedure
\end{algorithmic}
\caption{Euclid’s algorithm}\label{algo1}
\end{subalgorithm}%
\begin{subalgorithm}{.5\textwidth}
\begin{algorithmic}[1]
  \Procedure{Euclid}{$a,b$}\Comment{The g.c.d. of a and b}
    \State $r\gets a\bmod b$
    \While{$r\not=0$}\Comment{We have the answer if r is 0}
      \State $a\gets b$
      \State $b\gets r$
      \State $r\gets a\bmod b$
    \EndWhile
    \State \textbf{return} $b$\Comment{The gcd is b}
  \EndProcedure
\end{algorithmic}
\caption{Euclid’s algorithm}\label{algo2}
\end{subalgorithm}
\captionsetup{labelformat=alglabel}
\caption{Two algorithms}%
\label{tab:1}%
\end{table}
Amazing CLI - also enables configuration files applied before framework starts
\section{Testing}
Add testing bit
\\\\
\hspace*{3em} After modular testing was completed the final step was to ensure that the manager framework worked as a whole and did indeed affect the amount of memory an isolate could utilise. The graph below shows the evolution of the heap size of an isolate controlled with the manager framework:
\begin{figure}[!ht]
  \centering
    \includegraphics[width=1.0\textwidth]{ControlWorks.png}
  \caption{Controlling heap size.}
\end{figure}

\chapter{Evaluation}
How isolates are mapped as individuals, what the gini is applied to.
Throughput, heap, footprint, limit, distance to limit.
\section{Equal Share Policy}
\begin{equation}
\textit{HardHeapLimit}_i = \textit{MaximumMemoryPerMachine} \times \frac{1}{\textit{NumberOfActiveIsolates}}
\end{equation}
\section{Inverse Throughput Policy}
\begin{equation}
\textit{Total Throughput} = \sum_{i=0}^{N} -\log_2(\frac{t_i}{1000})
\end{equation}
\begin{equation}
\textit{Hard Heap Limit}_i = \textit{MaximumMemoryPerMachine} \times \frac{-\log_2(\frac{t_i}{1000})}{\textit{Total Throughput}}
\end{equation}
\section{Robin Hood Policy}
Definitions: Isolate(h,a,t,L) h is the used heap memory, a is the unused heap memory, L is the maximum allowed heap size, t is the throughput. N is the total number of isolates running on a machine, P is the number of poor isolates, R is the number of rich isolates. 
\begin{equation}
\textit{Immediate Budget} = \textit{Total Allowed Memory} - \sum_{i=0}^{N}L_i
\end{equation}
\begin{equation}
Need_i     = Max(0,h_i \frac{-\log_2{t_i}}{2} - L_i)
\end{equation}
\begin{equation}
\textit{Total Need} = \sum_{i=0}^{P}Need_i
\end{equation}
\begin{equation}
\textit{OverflowNeed}     = Max(0,\textit{TotalNeed} - \textit{ImmediateBudget}) 
\end{equation}
\begin{equation}
\textit{AllocatableNeed}     = Max(0,\textit{TotalNeed} - \textit{OverflowNeed}) 
\end{equation}
\begin{equation}
\textit{StealAllowance} = Min(0.5,\frac{\textit{OverflowNeed}}{\sum_{i=0}^{R}L_i}) 
\end{equation}
\begin{equation}
\textit{AllocateAllowance} = \frac{\textit{AllocatableNeed}}{\textit{TotalNeed}} \times Min(1.0,\frac{\textit{AllocatableNeed}}{\textit{ImmediateBudget}}) 
\end{equation}
\begin{equation}
\textit{GiveAllowance} = \frac{\textit{OverflowNeed}}{\textit{TotalNeed}} \times Min(1.0,\frac{\textit{OverflowNeed}}{\textit{TotalStolen}}) 
\end{equation}
\begin{equation}
Steal_i = \textit{StealAllowance} \times L_i 
\end{equation}
\begin{equation}
Give_i = (\textit{GiveAllowance} + \textit{AllocateAllowance}) \times Need_i 
\end{equation}

\section{Wealth Redistribution}
\begin{equation}
\textit{WelfareIndex}_i = 0.75\times (1 - \frac{max(0,L_i - H_i)}{L_i})+0.20\times (1 - \frac{H_i}{\textit{MaxH}})+0.05\times \frac{t_i}{100}
\end{equation}

\begin{equation}
\textit{GivePotential}_i = max(0,L_1 - h_i)
\end{equation}

\begin{equation}
\textit{NeedPotential}_i = 1 - \textit{WelfareIndex}_i
\end{equation}

\begin{equation}
\textit{TotalGivePotential} = \sum_{i=0}^{N}\textit{GivePotential}_i
\end{equation}

\begin{equation}
\textit{TotalNeedPotential} = \sum_{i=0}^{N}\textit{NeedPotential}_i
\end{equation}

\begin{equation}
\textit{Redistribute} = min(TotalGivePotential,\textit{TotalMachineMemory} \times \textit{gini}(\textit{WelfareIndex}))
\end{equation}
Where MaxH is the maximum observed H (footPrint) and 100 is the maximum throughput that the V8 will report.
\begin{equation}
\textit{Available} = max(0,\textit{TotalMachineMemory} - \sum_{i=0}^{N}L_i)
\end{equation}

\begin{equation}
\textit{Take} = max(0,\textit{Redistribute} - \textit{Available})
\end{equation}

\begin{equation}
L_i = L_i - \frac{\textit{GivePotential}_i}{\textit{TotalGivePotential}} \times Take + \frac{\textit{NeedPotential}_i}{\textit{TotalNeedPotential}}\times (Available + Take) 
\end{equation}

\section{Pascal}
\chapter{Conclusion}
\section{Future Work}
Attach the 
Add security
Control Semi Space?
State based policy

\begin{appendices}
\chapter{Benchmark Scripts}
The contents...
\chapter{Minimum Heap Size Measurements}
\label{minheapsize}
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpBinaryTree.png}
    \caption{Binary Tree Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpFasta.png}
    \caption{Fasta Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpKNucleotide.png}
    \caption{KNucleotide Benchmark.}
\end{figure}

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.95\textwidth]{MHCmpRegexDNA.png}
    \caption{RegexDNA Benchmark.}
\end{figure}

\end{appendices}

%more accurate biblio
\begin{thebibliography}{9}
\bibitem{intro}
Gregor Richards, Andreas Gal, Brendan Eich, Jan Vitek,
\emph{Automated Construction of JavaScript Benchmarks},
\bibitem{v8gctour}
A tour of the V8 garbage collector,
\url{http://jayconrod.com/posts/55/a-tour-of-v8-garbage-collection},
\bibitem{nodejs}
NWJS Project
\url{http://nwjs.io/}
\bibitem{nwjs}
NodeJS Project
\url{https://nodejs.org/en/}
\bibitem{v8}
V8 Engine
\url{https://developers.google.com/v8/}
\bibitem{spidermk}
SpidermonkeyEngine
\url{https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey}
\bibitem{chakra}
Chackra Engine
\url{https://github.com/Microsoft/ChakraCore}
\bibitem{forseti}
Callum Cameron, Jeremy Singer, David Vengerov
\emph{The Judgment of Forseti: Economic Utility for Dynamic Heap Sizing of Multiple Runtimes},
\bibitem{powderplayer}
\url{https://github.com/jaruba/PowderPlayer}
\bibitem{whatsap}
\url{https://web.whatsapp.com/}
\bibitem{messenger}
\url{http://messengerfordesktop.com/}
\bibitem{devkit}
\url{https://github.com/printhom/devkit-core}
\bibitem{wunderlist}
\url{https://www.wunderlist.com/download/}
\bibitem{tycoongame}
\url{http://www.greenheartgames.com/app/game-dev-tycoon/}
\bibitem{welfareeconomics}
Deardorff, Alan V. (2014), "Welfare economics", Deardorffs' Glossary of International Economics \url{http://www-personal.umich.edu/~alandear/glossary/w.html#WelfareEconomics}
\bibitem{socialwelfarefunction}
Amartya K. Sen, 1970 [1984], Collective Choice and Social Welfare, ch. 3, "Collective Rationality." p. 33, and ch. 3*, "Social Welfare Functions." \url{http://www.citeulike.org/user/rlai/article/681900}
\bibitem{jsgrandpa}
Naomi Hamilton, “The A–Z of Programming Languages: JavaScript,” Computerworld, July 30, 2008, \url{http://bit.ly/1lKldIe}
\bibitem{jsdaddy}
 Paul Krill, “JavaScript Creator Ponders Past, Future,” InfoWorld, June 23, 2008, http://bit.ly/1lKlpXO; Brendan Eich, “A Brief History of JavaScript,” July 21, 2010, \url{http://bit.ly/1lKkI0M}
\bibitem{github}
GitHub, version control service based on git \hspace*{1em} \url{https://github.com/}
\bibitem{githut}
GitHut, Statistics for GitHub \hspace*{1em} \url{http://githut.info/}
\bibitem{gcpaper}
Paul R Wilson. Uniprocessor garbage collection techniques. In Memory Management, pages 1–42.
Springer, 1992.
\bibitem{v8sizebug}
V8 Maximum Memory Amount Per Isolate
\url{https://bugs.chromium.org/p/v8/issues/detail?id=847}
\bibitem{matplotlib}
Matplotlib library for python
\url{http://matplotlib.org/}
\end{thebibliography}
\end{document}